qlogin #I do this every time I log onto the cluster

cd /scratch/jms53460/7_2024_Ns
cp /home/jms53460/Ns_N-masked_genome.fa .
cp /home/jms53460/Ns_N-masked_hisat2_index* .
cp /home/jms53460/Ns_SNPs3.tab .

cp /home/jms53460/CELSeq_barcodes.txt .
mkdir Raw_Data


###Downloaded raw data from Duke onto the cluster
cp /work/bnlab/July2024Sequencing/Somers_10237_240830A9/T104-115* Raw_Data


###Install fastq-multx and subread
ml Miniconda3/23.5.2-0
conda create -p /scratch/jms53460/7_2024_Ns/Fastq-Multx -c bioconda fastq-multx -y 
source activate /scratch/jms53460/7_2024_Ns/Fastq-Multx
fastq-multx
conda deactivate

ml purge
ml Miniconda3/23.5.2-0
conda create -p subread-env -y
source activate ./subread-env/
conda install -c bioconda subread -y
subread-align
conda deactivate


###Demultiplex the raw data

#!/bin/bash
#SBATCH --job-name=Ns_demultiplex                                         # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=6                                                 # Number of cores per task
#SBATCH --mem=50gb                                                       # Total memory for job
#SBATCH --time=2:00:00                                                   # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/7_2024_Ns/Ns_dm.out                  # Location of standard output file
#SBATCH --error=/scratch/jms53460/7_2024_Ns/Ns_dm.err                   # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/7_2024_Ns
mkdir Demultiplexed
ml Miniconda3/23.5.2-0
source activate /scratch/jms53460/7_2024_Ns/Fastq-Multx

for file in Raw_Data/*_R1_*.gz; do
    filename=$(basename "$file")
    file2=$(echo "$filename" | sed 's/_R1.*//' | sed 's/_R2_001.fastq.gz//')

    if [ ! -f "Demultiplexed/""$file2""_dT-1s.fastq.gz" ]; then
        module load fastp/0.23.2-GCC-11.3.0
	    fastp -w 6 -i "$file" -I "Raw_Data/""$file2""_R2_001.fastq.gz" -o "Demultiplexed/umi_""$file2""_R1.fastq.gz" -O "Demultiplexed/umi_""$file2""_R2.fastq.gz" -A -Q -L -G --umi --umi_loc read2 --umi_len 10 --umi_prefix UMI

	    fastq-multx -b -B "CELSeq_barcodes.txt" -m 0 "Demultiplexed/umi_""$file2""_R2.fastq.gz" "Demultiplexed/umi_""$file2""_R1.fastq.gz" -o "Demultiplexed/""$file2""_%_R2.fastq.gz" "Demultiplexed/""$file2""_%.fastq.gz"  # Split read 2 file by CELseq barcodes. Require perfect match to barcode in expected location

	    find "Demultiplexed/" -name "umi_*" -delete
	    find "Demultiplexed/" -name "*_R2*" -delete
    fi
done
conda deactivate

mkdir hisat2_out

for file in "Demultiplexed/"*.fastq*
do
	file2="${file:14:-9}"

if [ ! -f "hisat2_out/""$file2"".bam" ]; then

	module load fastp/0.23.2-GCC-11.3.0
	fastp -w 6 -i "$file" -o "hisat2_out/""$file2"".fastq.gz" -y -x -3 -a AAAAAAAAAAAA

fi
done


###Takes ~20-30 mins per file pair (set of 96)


#Map to genome (hisat2), .bam output (samtools view), sort (samtools sort), index (samtools index)

#!/bin/bash
#SBATCH --job-name=Ns_hisat2                                              # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=6                                                 # Number of cores per task
#SBATCH --mem=50gb                                                        # Total memory for job
#SBATCH --time=2:00:00                                                   # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/7_2024_Ns/Ns_hs2.out                 # Location of standard output file
#SBATCH --error=/scratch/jms53460/7_2024_Ns/Ns_hs2.err                  # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/7_2024_Ns
ml HISAT2/3n-20201216-gompi-2022a
ml SAMtools/1.16.1-GCC-11.3.0
for file in "hisat2_out/"*s.fastq*
do
	file2="${file:11:-9}"

if [ ! -f "hisat2_out/""$file2"".bam" ]; then

	hisat2 -p 6 --dta -x Ns_N-masked_hisat2_index -U "hisat2_out/""$file2"".fastq.gz" | samtools view -bS -> "hisat2_out/""$file2""_unsorted.bam"
	samtools sort -@ 6 "hisat2_out/""$file2""_unsorted.bam" -o "hisat2_out/""$file2""_s.bam"
    samtools index -@ 6 "hisat2_out/""$file2""_s.bam"
	
fi
done


###Takes ~20-30 mins per set of 96


###Running SNPsplit and stringtie

#!/bin/bash
#SBATCH --job-name=Ns_SNPsplit_stringtie                                            # Job name
#SBATCH --partition=batch                                                           # Partition (queue) name
#SBATCH --ntasks=1                                                                  # Single task job
#SBATCH --cpus-per-task=6                                                           # Number of cores per task
#SBATCH --mem=50gb                                                                  # Total memory for job
#SBATCH --time=6:00:00                                                             # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/7_2024_Ns/Ns_SNPsplit_stringtie.out            # Location of standard output file
#SBATCH --error=/scratch/jms53460/7_2024_Ns/Ns_SNPsplit_stringtie.err             # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                                # Where to send mail
#SBATCH --mail-type=END,FAIL                                                        # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/7_2024_Ns
mkdir SNPsplit
ml SAMtools/1.16.1-GCC-11.3.0
ml SNPsplit/0.6.0-GCC-11.3.0-Perl-5.34.1
for file in "hisat2_out/"*_s.bam
do
    file2="${file:11:-6}"

    SNPsplit --conflicting -o SNPsplit --snp_file Ns_SNPs3.tab "$file"
    samtools sort -@ 6 SNPsplit/"$file2"_s.allele_flagged.bam -o SNPsplit/"$file2"_SNPsplit.bam
    
done

for file in "SNPsplit/"*_s.genome1.bam
do
    file2="${file:9:-14}"
    samtools sort -@ 6 "$file" -o SNPsplit/"$file2"_SNPsplit_g1.bam
done

for file in "SNPsplit/"*_s.genome2.bam
do
    file2="${file:9:-14}"
    samtools sort -@ 6 "$file" -o SNPsplit/"$file2"_SNPsplit_g2.bam
done

ml StringTie/2.2.1-GCC-11.3.0
mkdir stringtie_out
for file in "hisat2_out/"*_s.bam
do
	stringtie -p 6 --rf -o "stringtie_out/""${file:11:-6}"".gtf" "$file"
done

# Merge StringTie transcripts
ls -1 "stringtie_out/"*.gtf | gawk '{print $0}' > mergelist.txt

# Merge GTF files
stringtie --merge -p 6 -o "stringtie_out/stringtie_merged.gtf" mergelist.txt
rm mergelist.txt


###Takes ~30 mins per set of 96
###I had an error when merging into one gtf file because 44s was empty. I removed 44s gtf and then it ran fine


#!/bin/bash
#SBATCH --job-name=Ns_features_UMIs                                           # Job name
#SBATCH --partition=batch                                                     # Partition (queue) name
#SBATCH --ntasks=1                                                            # Single task job
#SBATCH --cpus-per-task=6                                                     # Number of cores per task
#SBATCH --mem=50gb                                                            # Total memory for job
#SBATCH --time=12:00:00                                                       # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/7_2024_Ns/Ns_features_UMIs.out           # Location of standard output file
#SBATCH --error=/scratch/jms53460/7_2024_Ns/Ns_features_UMIs.err            # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                          # Where to send mail
#SBATCH --mail-type=END,FAIL                                                  # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/7_2024_Ns
mkdir featurecounts
mkdir bams
mkdir UMIcounts
mkdir UMIcounts_g1
mkdir UMIcounts_g2
ml purge_dups/1.2.5-foss-2021b
ml Miniconda3/23.5.2-0
source activate ./subread-env/

featureCounts -T 6 -s 1 -a stringtie_out/stringtie_merged.gtf -o featurecounts/read_counts.tab --readExtension5 500 -R BAM SNPsplit/*_SNPsplit.bam
featureCounts -T 6 -s 1 -a stringtie_out/stringtie_merged.gtf -o featurecounts/read_counts_g1.tab --readExtension5 500 -R BAM SNPsplit/*_SNPsplit_g1.bam
featureCounts -T 6 -s 1 -a stringtie_out/stringtie_merged.gtf -o featurecounts/read_counts_g2.tab --readExtension5 500 -R BAM SNPsplit/*_SNPsplit_g2.bam

conda deactivate

for file in "featurecounts/"*SNPsplit.bam*
do
    file2="${file:14:-22}"
    if [ ! -f "UMIcounts/${file2}.tsv" ]; then

        module load SAMtools/1.16.1-GCC-11.3.0
        samtools sort -@ 6 "$file" -o "bams/$file2"
        samtools index "bams/$file2"

        module load UMI-tools/1.1.2-foss-2022a-Python-3.10.4
        umi_tools count --per-gene --gene-tag=XT --assigned-status-tag=XS -I "bams/$file2" -S "UMIcounts/${file2}.tsv"
    fi
done

for file in "featurecounts/"*g1.bam*
do
    file2="${file:14:-22}"
    if [ ! -f "UMIcounts_g1/${file2}.tsv" ]; then

        module load SAMtools/1.16.1-GCC-11.3.0
        samtools sort -@ 6 "$file" -o "bams/$file2"
        samtools index "bams/$file2"

        module load UMI-tools/1.1.2-foss-2022a-Python-3.10.4
        umi_tools count --per-gene --gene-tag=XT --assigned-status-tag=XS -I "bams/$file2" -S "UMIcounts_g1/${file2}.tsv"
    fi
done

for file in "featurecounts/"*g2.bam*
do
    file2="${file:14:-22}"
    if [ ! -f "UMIcounts_g2/${file2}.tsv" ]; then

        module load SAMtools/1.16.1-GCC-11.3.0
        samtools sort -@ 6 "$file" -o "bams/$file2"
        samtools index "bams/$file2"

        module load UMI-tools/1.1.2-foss-2022a-Python-3.10.4
        umi_tools count --per-gene --gene-tag=XT --assigned-status-tag=XS -I "bams/$file2" -S "UMIcounts_g2/${file2}.tsv"
    fi
done


ml R/4.3.1-foss-2022a
R
annots = strsplit(read.table('stringtie_out/stringtie_merged.gtf', sep = '\t')[,9], ';')
annots = annots[grep('gene_id', annots)]
names(annots) = unlist(lapply(annots, function(xx) { xx[1] }))
names(annots) = sub('gene_id ', '', names(annots))
annots = annots[!duplicated(names(annots))]
annots = sub(';', '', sub(' ', '', unlist(lapply(annots, function(xx) { sub('.+ ', '', if (length(xx) == 3) { xx[3] } else { xx[1] }) }))))

files = dir('UMIcounts')
A = matrix(NA, nrow = length(annots), ncol = length(files))
rownames(A) = names(annots)
colnames(A) = files
for (f in files) {
	xx = read.table(paste('UMIcounts/', f, sep = ''), sep = '\t', header=T, row.names=1)
	A[,f] = xx[match(names(annots),rownames(xx)),1]
}
colnames(A) = sub('_S95_L003', '', sub('_SNPsplit.tsv', '', files))
A[is.na(A)] = 0
B = A

files = dir('UMIcounts_g1')
A = matrix(NA, nrow = length(annots), ncol = length(files))
rownames(A) = names(annots)
colnames(A) = files
for (f in files) {
	xx = read.table(paste('UMIcounts_g1/', f, sep = ''), sep = '\t', header=T, row.names=1)
	A[,f] = xx[match(names(annots),rownames(xx)),1]
}
colnames(A) = sub('L003_', '', sub('_SNPsplit_g1.tsv', '', files))
A[is.na(A)] = 0

g1 = A

files = dir('UMIcounts_g2')
A = matrix(NA, nrow = length(annots), ncol = length(files))
rownames(A) = names(annots)
colnames(A) = files
for (f in files) {
	xx = read.table(paste('UMIcounts_g2/', f, sep = ''), sep = '\t', header=T, row.names=1)
	A[,f] = xx[match(names(annots),rownames(xx)),1]
}
colnames(A) = sub('L003_', '', sub('_SNPsplit_g2.tsv', '', files))
A[is.na(A)] = 0
g2 = A

genes = read.table('stringtie_out/stringtie_merged.gtf', sep = '\t')[,c(1,5)]
annots2 = strsplit(read.table('stringtie_out/stringtie_merged.gtf', sep = '\t')[,9], ';')
names(annots2) = unlist(lapply(annots2, function(xx) { xx[1] }))
genes[,3] = names(annots2)
genes = genes[!duplicated(genes[,3]),]
genes[,3] = names(annots)
colnames(genes) = c('Chr', 'Position', 'Gene')
rownames(genes) = genes[,3]

save(B,g1,g2,genes, file = "7_2024_Ns.RData")
q()


###Copying this to my local computer
scp sapelo2:/scratch/jms53460/7_2024_Ns/7_2024_Ns.RData 'C:/Users/julia/OneDrive/Desktop/Grad School/Nelms lab/Bioinformatics/R'


setwd('C:/Users/julia/OneDrive/Desktop/Grad School/Nelms lab/Bioinformatics/R')
load('7_2024_Ns.RData')

g1[rowSums(g1) == 0] = NA
g2[rowSums(g2) == 0] = NA


Ns_AlleleFrac = g1/(g1+g2)
Ns_AlleleFrac = Ns_AlleleFrac[which(rowSums(is.na(Ns_AlleleFrac)) <96),which(colSums(is.na(Ns_AlleleFrac)) < 27300)]

library('ComplexHeatmap')
Heatmap(Ns_AlleleFrac, name = 'Ns_AlleleFrac', col = colorRampPalette(c('#0571b0','#92c5de','#f7f7f7','#f4a582','#ca0020'))(100))


#Not enough data to work with at the moment. I'll try remaking the SNP table and N-masked genome using the new data



cp /home/jms53460/Ns_genome.fna .
cp /home/jms53460/Ns_genome.fna.fai .
cp /home/jms53460/hisat2_index* .
#removed old directories and files that used the previous N-masked genome and SNP table


#!/bin/bash
#SBATCH --job-name=Ns_hisat2_2                                              # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=6                                                 # Number of cores per task
#SBATCH --mem=50gb                                                        # Total memory for job
#SBATCH --time=2:00:00                                                   # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/7_2024_Ns/Ns_hs2_2.out                 # Location of standard output file
#SBATCH --error=/scratch/jms53460/7_2024_Ns/Ns_hs2_2.err                  # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/7_2024_Ns
mkdir hisat2_out

for file in "Demultiplexed/"*.fastq*
do
	file2="${file:14:-9}"

if [ ! -f "hisat2_out/""$file2"".bam" ]; then

	module load fastp/0.23.2-GCC-11.3.0
	fastp -w 6 -i "$file" -o "hisat2_out/""$file2"".fastq.gz" -y -x -3 -a AAAAAAAAAAAA

fi
done

mkdir hisat2_out2
cp hisat2_out/*s.fastq.gz hisat2_out2
ml HISAT2/3n-20201216-gompi-2022a
ml SAMtools/1.16.1-GCC-11.3.0
for file in "hisat2_out2/"*s.fastq*
do
	file2="${file:12:-9}"

if [ ! -f "hisat2_out2/""$file2"".bam" ]; then

	hisat2 -p 6 --dta -x Ns_hisat2_index -U "hisat2_out2/""$file2"".fastq.gz" | samtools view -bS -> "hisat2_out2/""$file2""_unsorted.bam"
	samtools sort -@ 6 "hisat2_out2/""$file2""_unsorted.bam" -o "hisat2_out2/""$file2""_s.bam"
    samtools index -@ 6 "hisat2_out2/""$file2""_s.bam"
	
fi
done


ls hisat2_out2/*_s.bam > bamlist


#!/bin/bash
#SBATCH --job-name=Ns_bcftools                                              # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=6                                                 # Number of cores per task
#SBATCH --mem=50gb                                                        # Total memory for job
#SBATCH --time=2:00:00                                                   # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/7_2024_Ns/Ns_bcftools.out                 # Location of standard output file
#SBATCH --error=/scratch/jms53460/7_2024_Ns/Ns_bcftools.err                  # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/7_2024_Ns
module load BCFtools/1.15.1-GCC-11.3.0
bcftools mpileup -Ou --threads 6 -d 1000 --min-MQ 60 --skip-indels -f Ns_genome.fna -b bamlist | bcftools call -Ou -m -v --threads 6 | bcftools filter -Oz -e 'QUAL<40 || DP<10' > Ns_2.vcf.gz
bcftools index Ns_2.vcf.gz



###Install vcf2tsvpy
ml Miniconda3/23.5.2-0
conda create -p /scratch/jms53460/7_2024_Ns/vcf2tsvpy -c bioconda vcf2tsvpy -y
source activate /scratch/jms53460/7_2024_Ns/vcf2tsvpy
vcf2tsvpy --help
conda deactivate


###Convert vcf to tsv

#!/bin/bash
#SBATCH --job-name=Ns_vcf2tsvpy                         # Job name
#SBATCH --partition=batch                               # Partition (queue) name
#SBATCH --ntasks=1                                      # Single task job
#SBATCH --cpus-per-task=6                               # Number of cores per task
#SBATCH --mem=50gb                                      # Total memory for job
#SBATCH --time=6:00:00                                  # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/7_2024_Ns/Ns_vcf2tsvpy.out        # Location of standard output file
#SBATCH --error=/scratch/jms53460/7_2024_Ns/Ns_vcf2tsvpy.err         # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                    # Where to send mail
#SBATCH --mail-type=END,FAIL                            # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/7_2024_Ns
ml Miniconda3/23.5.2-0
source activate /scratch/jms53460/7_2024_Ns/vcf2tsvpy
vcf2tsvpy --input_vcf Ns_2.vcf.gz --out_tsv Ns_2.vcf_table.tsv 
conda deactivate

#This failed because vcf2tsvpy is not working how it did before. The error suggests it's a problem with the python version or something like that.
#I found online that vcf files are basically already in tsv format but with headers, so I will try using the vcf file directly


zcat Ns_2.vcf.gz | grep -v "#" > Ns_2.tsv
awk '{print $1,$2,$3,$4,$5,$16}' Ns_2.tsv OFS="\t" > Ns_2_variants.tsv
awk '{print $6,$1,$2,$3,$4,$5}' Ns_2_variants.tsv OFS="\t" > Ns_2_SNPs.tsv


ml R/4.3.2-foss-2022b
R
Ns_SNPs_alt <- read.csv("/scratch/jms53460/7_2024_Ns/Ns_2_SNPs.tsv", sep="", header=FALSE)
Ns_SNPs = Ns_SNPs_alt[,(1:4)]
Ns_SNPs[,5] = paste(Ns_SNPs_alt[,5], "/", Ns_SNPs_alt[,6], sep = "")
colnames(Ns_SNPs) = c("ID", "Chr", "Position", "SNP value", "Ref/SNP")
Ns_SNPs$"ID" = "."
Ns_SNPs$"SNP value" = 1
dim(Ns_SNPs) # 14726 rows 5 columns
dim(Ns_SNPs[!duplicated(Ns_SNPs[,3]),]) #14725 rows 5 columns
which(duplicated(Ns_SNPs[,3])) #6559
Ns_SNPs[6559,] #Position is 131737018
which(Ns_SNPs[,3] == 131737018) #988 and 6559
Ns_SNPs[c(988,6559),] #The position number is the same but Chr is different, so there are no duplicate rows :)
write.table(Ns_SNPs, file = 'Ns_2_SNPs.tab', col.names = TRUE, row.names = FALSE, sep = '\t', quote = FALSE)
q()



#!/bin/bash
#SBATCH --job-name=Ns_bedtools_maskfasta                           # Job name
#SBATCH --partition=batch                                          # Partition (queue) name
#SBATCH --ntasks=1                                                 # Single task job
#SBATCH --cpus-per-task=1                                          # Number of cores per task
#SBATCH --mem=50gb                                                 # Total memory for job
#SBATCH --time=6:00:00                                             # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/7_2024_Ns/Ns_bedtools_maskfasta.out          # Location of standard output file
#SBATCH --error=/scratch/jms53460/7_2024_Ns/Ns_bedtools_maskfasta.err           # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                               # Where to send mail
#SBATCH --mail-type=END,FAIL                                       # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/7_2024_Ns
ml BEDTools/2.30.0-GCC-12.2.0
bedtools maskfasta -fi Ns_genome.fna -fo Ns_2_N-masked_genome.fa -bed Ns_2.vcf.gz -fullHeader

ml HISAT2/3n-20201216-gompi-2022a
hisat2-build Ns_2_N-masked_genome.fa Ns_2_N-masked_hisat2_index


#Chromosome names
grep 'chr' Ns_2_N-masked_genome.fa | head
>CM066003.1 Nicotiana sylvestris chromosome 1, whole genome shotgun sequence
>CM066004.1 Nicotiana sylvestris chromosome 2, whole genome shotgun sequence
>CM066005.1 Nicotiana sylvestris chromosome 3, whole genome shotgun sequence
>CM066006.1 Nicotiana sylvestris chromosome 4, whole genome shotgun sequence
>CM066007.1 Nicotiana sylvestris chromosome 5, whole genome shotgun sequence
>CM066008.1 Nicotiana sylvestris chromosome 6, whole genome shotgun sequence
>CM066009.1 Nicotiana sylvestris chromosome 7, whole genome shotgun sequence
>CM066010.1 Nicotiana sylvestris chromosome 8, whole genome shotgun sequence
>CM066011.1 Nicotiana sylvestris chromosome 9, whole genome shotgun sequence
>CM066012.1 Nicotiana sylvestris chromosome 10, whole genome shotgun sequence


#Map to genome (hisat2), .bam output (samtools view), sort (samtools sort), index (samtools index)

#!/bin/bash
#SBATCH --job-name=Ns_hisat2                                              # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=6                                                 # Number of cores per task
#SBATCH --mem=50gb                                                        # Total memory for job
#SBATCH --time=2:00:00                                                   # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/7_2024_Ns/Ns_hs2.out                 # Location of standard output file
#SBATCH --error=/scratch/jms53460/7_2024_Ns/Ns_hs2.err                  # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/7_2024_Ns
ml HISAT2/3n-20201216-gompi-2022a
ml SAMtools/1.16.1-GCC-11.3.0
for file in "hisat2_out/"*s.fastq*
do
	file2="${file:11:-9}"

if [ ! -f "hisat2_out/""$file2"".bam" ]; then

	hisat2 -p 6 --dta -x Ns_2_N-masked_hisat2_index -U "hisat2_out/""$file2"".fastq.gz" | samtools view -bS -> "hisat2_out/""$file2""_unsorted.bam"
	samtools sort -@ 6 "hisat2_out/""$file2""_unsorted.bam" -o "hisat2_out/""$file2""_s.bam"
    samtools index -@ 6 "hisat2_out/""$file2""_s.bam"
	
fi
done


###Takes ~20-30 mins per set of 96


###Running SNPsplit and stringtie

#!/bin/bash
#SBATCH --job-name=Ns_SNPsplit_stringtie                                            # Job name
#SBATCH --partition=batch                                                           # Partition (queue) name
#SBATCH --ntasks=1                                                                  # Single task job
#SBATCH --cpus-per-task=6                                                           # Number of cores per task
#SBATCH --mem=50gb                                                                  # Total memory for job
#SBATCH --time=6:00:00                                                             # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/7_2024_Ns/Ns_SNPsplit_stringtie.out            # Location of standard output file
#SBATCH --error=/scratch/jms53460/7_2024_Ns/Ns_SNPsplit_stringtie.err             # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                                # Where to send mail
#SBATCH --mail-type=END,FAIL                                                        # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/7_2024_Ns
mkdir SNPsplit
ml SAMtools/1.16.1-GCC-11.3.0
ml SNPsplit/0.6.0-GCC-11.3.0-Perl-5.34.1
for file in "hisat2_out/"*_s.bam
do
    file2="${file:11:-6}"

    SNPsplit --conflicting -o SNPsplit --snp_file Ns_2_SNPs.tab "$file"
    samtools sort -@ 6 SNPsplit/"$file2"_s.allele_flagged.bam -o SNPsplit/"$file2"_SNPsplit.bam
    
done

for file in "SNPsplit/"*_s.genome1.bam
do
    file2="${file:9:-14}"
    samtools sort -@ 6 "$file" -o SNPsplit/"$file2"_SNPsplit_g1.bam
done

for file in "SNPsplit/"*_s.genome2.bam
do
    file2="${file:9:-14}"
    samtools sort -@ 6 "$file" -o SNPsplit/"$file2"_SNPsplit_g2.bam
done

ml StringTie/2.2.1-GCC-11.3.0
mkdir stringtie_out
for file in "hisat2_out/"*_s.bam
do
	stringtie -p 6 --rf -o "stringtie_out/""${file:11:-6}"".gtf" "$file"
done

# Merge StringTie transcripts
ls -1 "stringtie_out/"*.gtf | gawk '{print $0}' > mergelist.txt

# Merge GTF files
stringtie --merge -p 6 -o "stringtie_out/stringtie_merged.gtf" mergelist.txt
rm mergelist.txt


###Takes ~30 mins per set of 96
###I had an error when merging into one gtf file because 44s was empty. I removed 44s gtf and then it ran fine


#!/bin/bash
#SBATCH --job-name=Ns_features_UMIs                                           # Job name
#SBATCH --partition=batch                                                     # Partition (queue) name
#SBATCH --ntasks=1                                                            # Single task job
#SBATCH --cpus-per-task=6                                                     # Number of cores per task
#SBATCH --mem=50gb                                                            # Total memory for job
#SBATCH --time=12:00:00                                                       # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/7_2024_Ns/Ns_features_UMIs.out           # Location of standard output file
#SBATCH --error=/scratch/jms53460/7_2024_Ns/Ns_features_UMIs.err            # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                          # Where to send mail
#SBATCH --mail-type=END,FAIL                                                  # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/7_2024_Ns
mkdir featurecounts
mkdir bams
mkdir UMIcounts
mkdir UMIcounts_g1
mkdir UMIcounts_g2
ml purge_dups/1.2.5-foss-2021b
ml Miniconda3/23.5.2-0
source activate ./subread-env/

featureCounts -T 6 -s 1 -a stringtie_out/stringtie_merged.gtf -o featurecounts/read_counts.tab --readExtension5 500 -R BAM SNPsplit/*_SNPsplit.bam
featureCounts -T 6 -s 1 -a stringtie_out/stringtie_merged.gtf -o featurecounts/read_counts_g1.tab --readExtension5 500 -R BAM SNPsplit/*_SNPsplit_g1.bam
featureCounts -T 6 -s 1 -a stringtie_out/stringtie_merged.gtf -o featurecounts/read_counts_g2.tab --readExtension5 500 -R BAM SNPsplit/*_SNPsplit_g2.bam

conda deactivate

for file in "featurecounts/"*SNPsplit.bam*
do
    file2="${file:14:-22}"
    if [ ! -f "UMIcounts/${file2}.tsv" ]; then

        module load SAMtools/1.16.1-GCC-11.3.0
        samtools sort -@ 6 "$file" -o "bams/$file2"
        samtools index "bams/$file2"

        module load UMI-tools/1.1.2-foss-2022a-Python-3.10.4
        umi_tools count --per-gene --gene-tag=XT --assigned-status-tag=XS -I "bams/$file2" -S "UMIcounts/${file2}.tsv"
    fi
done

for file in "featurecounts/"*g1.bam*
do
    file2="${file:14:-22}"
    if [ ! -f "UMIcounts_g1/${file2}.tsv" ]; then

        module load SAMtools/1.16.1-GCC-11.3.0
        samtools sort -@ 6 "$file" -o "bams/$file2"
        samtools index "bams/$file2"

        module load UMI-tools/1.1.2-foss-2022a-Python-3.10.4
        umi_tools count --per-gene --gene-tag=XT --assigned-status-tag=XS -I "bams/$file2" -S "UMIcounts_g1/${file2}.tsv"
    fi
done

for file in "featurecounts/"*g2.bam*
do
    file2="${file:14:-22}"
    if [ ! -f "UMIcounts_g2/${file2}.tsv" ]; then

        module load SAMtools/1.16.1-GCC-11.3.0
        samtools sort -@ 6 "$file" -o "bams/$file2"
        samtools index "bams/$file2"

        module load UMI-tools/1.1.2-foss-2022a-Python-3.10.4
        umi_tools count --per-gene --gene-tag=XT --assigned-status-tag=XS -I "bams/$file2" -S "UMIcounts_g2/${file2}.tsv"
    fi
done


ml R/4.3.1-foss-2022a
R
annots = strsplit(read.table('stringtie_out/stringtie_merged.gtf', sep = '\t')[,9], ';')
annots = annots[grep('gene_id', annots)]
names(annots) = unlist(lapply(annots, function(xx) { xx[1] }))
names(annots) = sub('gene_id ', '', names(annots))
annots = annots[!duplicated(names(annots))]
annots = sub(';', '', sub(' ', '', unlist(lapply(annots, function(xx) { sub('.+ ', '', if (length(xx) == 3) { xx[3] } else { xx[1] }) }))))

files = dir('UMIcounts')
A = matrix(NA, nrow = length(annots), ncol = length(files))
rownames(A) = names(annots)
colnames(A) = files
for (f in files) {
	xx = read.table(paste('UMIcounts/', f, sep = ''), sep = '\t', header=T, row.names=1)
	A[,f] = xx[match(names(annots),rownames(xx)),1]
}
colnames(A) = sub('_S95_L003', '', sub('_SNPsplit.tsv', '', files))
A[is.na(A)] = 0
B = A

files = dir('UMIcounts_g1')
A = matrix(NA, nrow = length(annots), ncol = length(files))
rownames(A) = names(annots)
colnames(A) = files
for (f in files) {
	xx = read.table(paste('UMIcounts_g1/', f, sep = ''), sep = '\t', header=T, row.names=1)
	A[,f] = xx[match(names(annots),rownames(xx)),1]
}
colnames(A) = sub('L003_', '', sub('_SNPsplit_g1.tsv', '', files))
A[is.na(A)] = 0

g1 = A

files = dir('UMIcounts_g2')
A = matrix(NA, nrow = length(annots), ncol = length(files))
rownames(A) = names(annots)
colnames(A) = files
for (f in files) {
	xx = read.table(paste('UMIcounts_g2/', f, sep = ''), sep = '\t', header=T, row.names=1)
	A[,f] = xx[match(names(annots),rownames(xx)),1]
}
colnames(A) = sub('L003_', '', sub('_SNPsplit_g2.tsv', '', files))
A[is.na(A)] = 0
g2 = A

genes = read.table('stringtie_out/stringtie_merged.gtf', sep = '\t')[,c(1,5)]
annots2 = strsplit(read.table('stringtie_out/stringtie_merged.gtf', sep = '\t')[,9], ';')
names(annots2) = unlist(lapply(annots2, function(xx) { xx[1] }))
genes[,3] = names(annots2)
genes = genes[!duplicated(genes[,3]),]
genes[,3] = names(annots)
colnames(genes) = c('Chr', 'Position', 'Gene')
rownames(genes) = genes[,3]
genes = genes[order(genes[,1]),]
genes[,1] = sub('CM06600', '', genes[,1])
genes[,1] = sub('CM0660', '', genes[,1])


genes1 = genes[which(genes[,1] == 3.1),]
genes1 = genes1[order(genes1[,2]),]
genes1[,1] = 1
genes2 = genes[which(genes[,1] == 4.1),]
genes2 = genes2[order(genes2[,2]),]
genes2[,1] = 2
genes3 = genes[which(genes[,1] == 5.1),]
genes3 = genes3[order(genes3[,2]),]
genes3[,1] = 3
genes4 = genes[which(genes[,1] == 6.1),]
genes4 = genes4[order(genes4[,2]),]
genes4[,1] = 4
genes5 = genes[which(genes[,1] == 7.1),]
genes5 = genes5[order(genes5[,2]),]
genes5[,1] = 5
genes6 = genes[which(genes[,1] == 8.1),]
genes6 = genes6[order(genes6[,2]),]
genes6[,1] = 6
genes7 = genes[which(genes[,1] == 9.1),]
genes7 = genes7[order(genes7[,2]),]
genes7[,1] = 7
genes8 = genes[which(genes[,1] == 10.1),]
genes8 = genes8[order(genes8[,2]),]
genes8[,1] = 8
genes9 = genes[which(genes[,1] == 11.1),]
genes9 = genes9[order(genes9[,2]),]
genes9[,1] = 9
genes10 = genes[which(genes[,1] == 12.1),]
genes10 = genes10[order(genes10[,2]),]
genes10[,1] = 10

genes = rbind(genes1, genes2, genes3, genes4, genes5, genes6, genes7, genes8, genes9, genes10)
B = B[rownames(genes),]
g1 = g1[rownames(genes),]
g2 = g2[rownames(genes),]

save(B,g1,g2,genes, file = "7_2024_Ns_2.RData")
q()


###Copying this to my local computer
scp sapelo2:/scratch/jms53460/7_2024_Ns/7_2024_Ns_2.RData 'C:/Users/julia/OneDrive/Desktop/Grad School/Nelms lab/Bioinformatics/R'



setwd('C:/Users/julia/OneDrive/Desktop/Grad School/Nelms lab/Bioinformatics/R')
load('7_2024_Ns_2.RData')

> summary(colSums(B))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
    3.0   811.8  1441.0  2737.8  3260.2 22528.0

> summary(colSums(g1))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
    1.0   328.5   594.0  1181.8  1338.8 11762.0

> summary(colSums(g2))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
    0.0    30.0    61.5   148.0   220.2  1348.0

BIN2 = function (xx, bin = 10^7) 
{
    bin = as.numeric(genes[, 1]) * 10^7 + round(genes[, 2]/bin)
    out = by(xx, bin, colSums)
    out2 = t(matrix(unlist(out), nrow = ncol(g1)))
    colnames(out2) = colnames(g1)
    rownames(out2) = names(out)
    return(out2)
}

library(ggplot2)
library(ggpubr)
g1_bin = BIN2(g1)
g2_bin = BIN2(g2)
g1_frac = g1_bin/(g1_bin + g2_bin*8) #Multiplying g2_bin amounts by 8 to account for huge difference in g1 and g2 colSums ~8-10 fold difference
AlleleFrac = g1_frac
AlleleFrac[(g1_bin+g2_bin) < 3] = NA #remove bins with <3 genoinformative transcripts
AlleleFrac[(g2_bin < 1)] = NA
AlleleFrac2 = AlleleFrac[,which(colSums(is.na(AlleleFrac)) <= 150)]


library('ComplexHeatmap')

Heatmap(AlleleFrac2, name = 'AlleleFrac', col = colorRampPalette(c('#0571b0','#92c5de','#f7f7f7','#f4a582','#ca0020'))(100), cluster_rows=F, cluster_columns=T)



###Make a merged bam file and index file to load into IGV

#!/bin/bash
#SBATCH --job-name=Ns_samtools_merge                                      # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=6                                                 # Number of cores per task
#SBATCH --mem=50gb                                                        # Total memory for job
#SBATCH --time=2:00:00                                                    # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/7_2024_Ns/Ns_samtools_merge.out        # Location of standard output file
#SBATCH --error=/scratch/jms53460/7_2024_Ns/Ns_samtools_merge.err         # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/7_2024_Ns
module load SAMtools/1.16.1-GCC-11.3.0
samtools merge -@ 6 -o 7_2024_Ns_merged.bam -b bamlist
samtools sort -@ 6 7_2024_Ns_merged.bam -o 7_2024_Ns_merged_s.bam
samtools index 7_2024_Ns_merged_s.bam


