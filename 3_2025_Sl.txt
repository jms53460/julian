Processing tomato data from March 2025 sequencing

ssh jms53460@xfer.gacrc.uga.edu
mkdir /work/bnlab/Feb2025seq


mkdir /scratch/jms53460/3_2025_Sl
cd /scratch/jms53460/3_2025_Sl
mkdir Raw_Data
cp /work/bnlab/Mar2025Seq/S* Raw_Data
cp /work/bnlab/Mar2025Seq/R* Raw_Data

###Also copying Ran's data here to demultiplex it (I only used 1s for hers, and three different XGEN), add UMIs to the headers, and trim the umi containing read.

cp /home/jms53460/CELSeq_barcodes.txt /scratch/jms53460/3_2025_Sl/
cp /home/jms53460/Sl_12.gff /scratch/jms53460/3_2025_Sl/
cp /home/jms53460/Sl_N-masked_genome* /scratch/jms53460/3_2025_Sl/
cp /home/jms53460/Sl_SNPs.tab /scratch/jms53460/3_2025_Sl/


#Demultiplex data in a way that it is nearly ready for upload with SRA.

#!/bin/bash
#SBATCH --job-name=Dm                                                     # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=6                                                 # Number of cores per task
#SBATCH --mem=50gb                                                        # Total memory for job
#SBATCH --time=12:00:00                                                   # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/3_2025_Sl/Dm.out                       # Location of standard output file
#SBATCH --error=/scratch/jms53460/3_2025_Sl/Dm.err                        # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/3_2025_Sl/
mkdir Demultiplexed
ml Miniconda3/23.5.2-0
source activate /home/jms53460/Fastq-Multx

for file in Raw_Data/*_R1_*.gz; do
    filename=$(basename "$file")
    file2=$(echo "$filename" | sed 's/_R1.*//' | sed 's/_R2_001.fastq.gz//')

    if [ ! -f "Demultiplexed/""$file2""_1s.fastq.gz" ]; then
        module load fastp/0.23.2-GCC-11.3.0
	    #Move UMI to header
        fastp -w 6 -i "$file" -I "Raw_Data/""$file2""_R2_001.fastq.gz" -o "Demultiplexed/umi_""$file2""_R1.fastq.gz" -O "Demultiplexed/umi_""$file2""_R2.fastq.gz" -A -Q -L -G --umi --umi_loc read2 --umi_len 10 --umi_prefix UMI
        
        #Split read 2 file by CELseq barcodes. Require perfect match to barcode in expected location
	    fastq-multx -b -B "CELSeq_barcodes.txt" -m 0 "Demultiplexed/umi_""$file2""_R2.fastq.gz" "Demultiplexed/umi_""$file2""_R1.fastq.gz" "Raw_Data/""$file2""_R2_001.fastq.gz" -o "Demultiplexed/""$file2""_%_R2.fastq.gz" "Demultiplexed/""$file2""_%.fastq.gz" "Demultiplexed/""$file2""_%_umi.fastq.gz"

    fi
done
conda deactivate


###Remove 2-96s files for Ran's data since I only used 1s
cd /scratch/jms53460/3_2025_Sl
mkdir Ran_empty
mv Demultiplexed/Ran* Ran_empty
mv Ran_empty/*_1s* Demultiplexed


###Trim UMI containing read to only the UMI

#!/bin/bash
#SBATCH --job-name=SRA_prep                                               # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=6                                                 # Number of cores per task
#SBATCH --mem=50gb                                                        # Total memory for job
#SBATCH --time=12:00:00                                                   # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/3_2025_Sl/SRA_prep.out                 # Location of standard output file
#SBATCH --error=/scratch/jms53460/3_2025_Sl/SRA_prep.err                  # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/3_2025_Sl/
mkdir SRA_upload
module load fastp/0.23.2-GCC-11.3.0

for file in Demultiplexed/*s.fastq.gz; do
	file2="${file:14:-9}"

    #Trim UMI containing read to only contain the UMI
    fastp -w 6 -B 10 -i "Demultiplexed/""$file2"".fastq.gz" -I "Demultiplexed/""$file2""_umi.fastq.gz" -o "SRA_upload/""$file2"".fastq.gz" -O "SRA_upload/""$file2""_umi.fastq.gz" -A -Q -L -G
done


###Move Ran's data out of folders with my data
cd /scratch/jms53460/3_2025_Sl
mkdir Ran_dm
mv Demultiplexed/Ran* Ran_dm
mkdir Ran_data
mv SRA_upload/Ran* Ran_data


#!/bin/bash
#SBATCH --job-name=Hisat2                                                 # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=6                                                 # Number of cores per task
#SBATCH --mem=50gb                                                        # Total memory for job
#SBATCH --time=12:00:00                                                   # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/3_2025_Sl/Hs2.out                      # Location of standard output file
#SBATCH --error=/scratch/jms53460/3_2025_Sl/Hs2.err                       # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/3_2025_Sl

module load fastp/0.23.2-GCC-11.3.0
mkdir hisat2_out
for file in Demultiplexed/*s.fastq.gz; do
	file2="${file:14:-9}"

if [ ! -f "hisat2_out/""$file2"".bam" ]; then

	fastp -w 6 -i "$file" -o "hisat2_out/""$file2"".fastq.gz" -y -x -3 -a AAAAAAAAAAAA

fi
done

ml HISAT2/3n-20201216-gompi-2022a
ml SAMtools/1.16.1-GCC-11.3.0
for file in hisat2_out/*s.fastq.gz
do
	file2="${file:11:-9}"

if [ ! -f "hisat2_out/""$file2"".bam" ]; then

	hisat2 -p 6 --dta -x Sl_N-masked_genome_index -U "hisat2_out/""$file2"".fastq.gz" | samtools view -bS -> "hisat2_out/""$file2""_unsorted.bam"
	samtools sort -@ 6 "hisat2_out/""$file2""_unsorted.bam" -o "hisat2_out/""$file2""_s.bam"
    samtools index -@ 6 "hisat2_out/""$file2""_s.bam"
	
fi
done


###Running SNPsplit

#!/bin/bash
#SBATCH --job-name=SNPsplit                                                         # Job name
#SBATCH --partition=batch                                                           # Partition (queue) name
#SBATCH --ntasks=1                                                                  # Single task job
#SBATCH --cpus-per-task=6                                                           # Number of cores per task
#SBATCH --mem=50gb                                                                  # Total memory for job
#SBATCH --time=6:00:00                                                              # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/3_2025_Sl/SNPsplit.out                       # Location of standard output file
#SBATCH --error=/scratch/jms53460/3_2025_Sl/SNPsplit.err                        # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                                # Where to send mail
#SBATCH --mail-type=END,FAIL                                                        # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/3_2025_Sl
mkdir SNPsplit
ml SAMtools/1.16.1-GCC-11.3.0
ml SNPsplit/0.6.0-GCC-11.3.0-Perl-5.34.1
for file in "hisat2_out/"*_s.bam
do
    file2="${file:11:-6}"

    SNPsplit --conflicting -o SNPsplit --snp_file Sl_SNPs.tab "$file"
    samtools sort -@ 6 SNPsplit/"$file2"_s.allele_flagged.bam -o SNPsplit/"$file2"_SNPsplit.bam
    
done

for file in "SNPsplit/"*_s.genome1.bam
do
    file2="${file:9:-14}"
    samtools sort -@ 6 "$file" -o SNPsplit/"$file2"_SNPsplit_g1.bam
done

for file in "SNPsplit/"*_s.genome2.bam
do
    file2="${file:9:-14}"
    samtools sort -@ 6 "$file" -o SNPsplit/"$file2"_SNPsplit_g2.bam
done


#!/bin/bash
#SBATCH --job-name=Features_UMIs                                              # Job name
#SBATCH --partition=batch                                                     # Partition (queue) name
#SBATCH --ntasks=1                                                            # Single task job
#SBATCH --cpus-per-task=6                                                     # Number of cores per task
#SBATCH --mem=50gb                                                            # Total memory for job
#SBATCH --time=12:00:00                                                       # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/3_2025_Sl/Features_UMIs.out            # Location of standard output file
#SBATCH --error=/scratch/jms53460/3_2025_Sl/Features_UMIs.err             # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                          # Where to send mail
#SBATCH --mail-type=END,FAIL                                                  # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/3_2025_Sl
mkdir featurecounts
mkdir bams
mkdir UMIcounts
mkdir UMIcounts_g1
mkdir UMIcounts_g2
ml purge_dups/1.2.5-foss-2021b
ml Miniconda3/23.5.2-0
source activate /home/jms53460/subread-env

featureCounts -T 6 -s 1 -a Sl_12.gff -t 'gene' -g 'ID' -o featurecounts/read_counts.tab --readExtension5 500 -R BAM SNPsplit/*_SNPsplit.bam
featureCounts -T 6 -s 1 -a Sl_12.gff -t 'gene' -g 'ID' -o featurecounts/read_counts_g1.tab --readExtension5 500 -R BAM SNPsplit/*_SNPsplit_g1.bam
featureCounts -T 6 -s 1 -a Sl_12.gff -t 'gene' -g 'ID' -o featurecounts/read_counts_g2.tab --readExtension5 500 -R BAM SNPsplit/*_SNPsplit_g2.bam

conda deactivate

for file in "featurecounts/"*SNPsplit.bam*
do
    file2="${file:14:-22}"
    if [ ! -f "UMIcounts/${file2}.tsv" ]; then

        module load SAMtools/1.16.1-GCC-11.3.0
        samtools sort -@ 6 "$file" -o "bams/$file2"
        samtools index "bams/$file2"

        module load UMI-tools/1.1.2-foss-2022a-Python-3.10.4
        umi_tools count --per-gene --gene-tag=XT --assigned-status-tag=XS -I "bams/$file2" -S "UMIcounts/${file2}.tsv"
    fi
done

for file in "featurecounts/"*g1.bam*
do
    file2="${file:14:-22}"
    if [ ! -f "UMIcounts_g1/${file2}.tsv" ]; then

        module load SAMtools/1.16.1-GCC-11.3.0
        samtools sort -@ 6 "$file" -o "bams/$file2"
        samtools index "bams/$file2"

        module load UMI-tools/1.1.2-foss-2022a-Python-3.10.4
        umi_tools count --per-gene --gene-tag=XT --assigned-status-tag=XS -I "bams/$file2" -S "UMIcounts_g1/${file2}.tsv"
    fi
done

for file in "featurecounts/"*g2.bam*
do
    file2="${file:14:-22}"
    if [ ! -f "UMIcounts_g2/${file2}.tsv" ]; then

        module load SAMtools/1.16.1-GCC-11.3.0
        samtools sort -@ 6 "$file" -o "bams/$file2"
        samtools index "bams/$file2"

        module load UMI-tools/1.1.2-foss-2022a-Python-3.10.4
        umi_tools count --per-gene --gene-tag=XT --assigned-status-tag=XS -I "bams/$file2" -S "UMIcounts_g2/${file2}.tsv"
    fi
done


ml R/4.3.1-foss-2022a
R
annots = strsplit(read.table('Sl_12.gff', sep = '\t', quote = "")[,9], ';')
annots = annots[grep('ID=gene-', annots)]
names(annots) = unlist(lapply(annots, function(xx) { xx[1] }))
names(annots) = sub('ID=', '', names(annots))
annots = annots[!duplicated(names(annots))]
annots = sub(';', '', sub(' ', '', unlist(lapply(annots, function(xx) { sub('.+ ', '', if (length(xx) == 3) { xx[3] } else { xx[1] }) }))))

files = dir('UMIcounts')
A = matrix(NA, nrow = length(annots), ncol = length(files))
rownames(A) = annots
colnames(A) = files
for (f in files) {
	xx = read.table(paste('UMIcounts/', f, sep = ''), sep = '\t', quote="", header=T, row.names=1)
	A[,f] = xx[match(names(annots),rownames(xx)),1]
}
colnames(A) = sub('_SNPsplit.tsv', '', sub('S2_L007_', '', files))
A[is.na(A)] = 0
#A = A[rowSums(A) > 0,]

B = A[order(rownames(A)),]
B2 = B
B = B[!duplicated(rownames(B)),]
for (g in unique(rownames(B)[duplicated(rownames(B))])) {
	B[g,] = colSums(B2[rownames(B2) %in% g,])
}
D = B

files = dir('UMIcounts_g1')
A = matrix(NA, nrow = length(annots), ncol = length(files))
rownames(A) = annots
colnames(A) = files
for (f in files) {
	xx = read.table(paste('UMIcounts_g1/', f, sep = ''), sep = '\t', quote="", header=T, row.names=1)
	A[,f] = xx[match(names(annots),rownames(xx)),1]
}
colnames(A) = sub('_SNPsplit_g1.tsv', '', sub('S2_L007_', '', files))
A[is.na(A)] = 0
#A = A[rowSums(A) > 0,]

B = A[order(rownames(A)),]
B2 = B
B = B[!duplicated(rownames(B)),]
for (g in unique(rownames(B)[duplicated(rownames(B))])) {
	B[g,] = colSums(B2[rownames(B2) %in% g,])
}
g1 = B

files = dir('UMIcounts_g2')
A = matrix(NA, nrow = length(annots), ncol = length(files))
rownames(A) = annots
colnames(A) = files
for (f in files) {
	xx = read.table(paste('UMIcounts_g2/', f, sep = ''), sep = '\t', quote="", header=T, row.names=1)
	A[,f] = xx[match(names(annots),rownames(xx)),1]
}
colnames(A) = sub('_SNPsplit_g2.tsv', '', sub('S2_L007_', '', files))
A[is.na(A)] = 0
#A = A[rowSums(A) > 0,]

B = A[order(rownames(A)),]
B2 = B
B = B[!duplicated(rownames(B)),]
for (g in unique(rownames(B)[duplicated(rownames(B))])) {
	B[g,] = colSums(B2[rownames(B2) %in% g,])
}
g2 = B

genes = read.table('Sl_12.gff', sep = '\t', quote = "")[,c(1,5)]
annots2 = strsplit(read.table('Sl_12.gff', sep = '\t', quote = "")[,9], ';')
names(annots2) = unlist(lapply(annots2, function(xx) { xx[1] }))
annots2 = sub(';', '', sub(' ', '', unlist(lapply(annots2, function(xx) { sub('.+ ', '', if (length(xx) == 3) { xx[3] } else { xx[1] }) }))))
genes[,3] = annots2
genes2 = genes[grepl('ID=gene-', genes[,3]),]
genes = genes2[order(genes2[,2]),] #order by position
genes = genes[order(genes[,1]),] #order by chr
genes = genes[!duplicated(genes[,3]),]
colnames(genes) = c('Chr', 'Position', 'Gene')
rownames(genes) = genes[,3]

D = D[rownames(genes),]
g1 = g1[rownames(genes),]
g2 = g2[rownames(genes),]
genes[,1] = sub('chr', '', genes[, 1])

D_Sl_3_2025 = D
g1_Sl_3_2025 = g1
g2_Sl_3_2025 = g2
Sl_genes = genes

save(D_Sl_3_2025,g1_Sl_3_2025,g2_Sl_3_2025,Sl_genes, file = "3_2025_Sl.RData")
q()



###Copying this to my local computer
scp sapelo2:/scratch/jms53460/3_2025_Sl/3_2025_Sl.RData 'C:/Users/julia/OneDrive/Desktop/Grad School/Nelms lab/Bioinformatics/R'

###In local R terminal
setwd('C:/Users/julia/OneDrive/Desktop/Grad School/Nelms lab/Bioinformatics/R')
load('3_2025_Sl.RData')

colnames(D_Sl_3_2025) = sub('S195_L004_', '', sub('S196_L004_', '', colnames(D_Sl_3_2025)))
colnames(g1_Sl_3_2025) = colnames(D_Sl_3_2025)
colnames(g2_Sl_3_2025) = colnames(D_Sl_3_2025)


library(readxl)
Sl_Stages_3_2025 <- read_excel("C:/Users/julia/OneDrive/Desktop/Grad School/Nelms lab/Bioinformatics/R/Sl_Stages_3_2025.xlsx")

Sl_meta_3_2025 <- Sl_Stages_3_2025[rep(row.names(Sl_Stages_3_2025), times = 8), ]
library(tidyverse)
Sl_meta_3_2025 = arrange(Sl_meta_3_2025, Bud_order)
Sl_meta_3_2025$Sample = c(paste(rep('S140-145_', times = 96), 1:96, rep('s', times=96), sep=''), paste(rep('S146-151_', times = 96), 1:96, rep('s', times=96), sep=''))
write.csv(Sl_meta_3_2025, "Sl_meta_3_2025.csv")
#edited in excel, saved as Sl_meta_3_2025.xlsx
Sl_meta_3_2025 <- read_excel("C:/Users/julia/OneDrive/Desktop/Grad School/Nelms lab/Bioinformatics/R/Sl_meta_3_2025.xlsx")
rownames(Sl_meta_3_2025) = Sl_meta_3_2025$Sample

D_Sl_3_2025 = D_Sl_3_2025[,Sl_meta_3_2025$Sample]
g1_Sl_3_2025 = g1_Sl_3_2025[,Sl_meta_3_2025$Sample]
g2_Sl_3_2025 = g2_Sl_3_2025[,Sl_meta_3_2025$Sample]

BIN3 = function (xx, bin = 10^6) 
{
    bin = as.numeric(Sl_genes[, 1]) * 10^6 + round(Sl_genes[, 2]/bin)
    out = by(xx, bin, colSums)
    out2 = t(matrix(unlist(out), nrow = ncol(g1_Sl_3_2025)))
    colnames(out2) = colnames(g1_Sl_3_2025)
    rownames(out2) = names(out)
    return(out2)
}

library(ggplot2)
library(ggpubr)
g1_bin_Sl_3_2025 = BIN3(g1_Sl_3_2025)
g2_bin_Sl_3_2025 = BIN3(g2_Sl_3_2025)
AlleleFrac_bin_Sl_3_2025 = g1_bin_Sl_3_2025/(g1_bin_Sl_3_2025 + g2_bin_Sl_3_2025)
AlleleFrac_bin_Sl_3_2025[(g1_bin_Sl_3_2025+g2_bin_Sl_3_2025) < 10] = NA #remove bins with <10 genoinformative transcripts
Sl_binUse_3_2025 = which(abs(rowMeans(AlleleFrac_bin_Sl_3_2025, na.rm=T) - .5) < .4)  # Exclude bins with >90% of all transcripts mapping to the same allele across all samples
AlleleFrac_bin_Sl_3_2025[-Sl_binUse_3_2025,] = NA
Sl_FracMono_all_3_2025 = 100*colMeans(abs(AlleleFrac_bin_Sl_3_2025 - .5) >= .3, na.rm=T)

Heatmap(AlleleFrac_bin_Sl_3_2025, name = 'Sl AlleleFrac 
2-2025',
    top_annotation = HeatmapAnnotation(UMIcounts = log(colSums(D_Sl_3_2025),10), 
    "No cell" = Sl_meta_3_2025$No_cell_well, "FracMono" = Sl_FracMono_all_3_2025, "Over 5,000 UMIs" = colSums(D_Sl_3_2025) > 5000,
    "Bud size" = Sl_meta_3_2025$"Bud_size_(mm)", "Collection" = Sl_meta_3_2025$Fixed_or_Fresh,
    col = list("No cell" = c("Y" = "#111111", "N" = "#eeeeee"), 
    "Over 5,000 UMIs" = c("TRUE" = "red3", "FALSE" = "blue3"), "Collection" = c("H2O" = "blue3", "Fixed_30" = "yellow3", "Mannitol" = "red3", "Mannitol_wash" = "pink"))),
    col = colorRampPalette(c('#0571b0','#92c5de','#f7f7f7','#f4a582','#ca0020'))(100), 
    cluster_rows=F, cluster_columns=F, show_row_names = F, show_column_names = F)


colSums(D_Sl_3_2025[,which(Sl_meta_3_2025$No_cell_well == "Y")])
S140-145_2s  S140-145_3s  S140-145_9s S140-145_10s S140-145_17s S140-145_24s 
        1953          657         2325         2411         4027         3039 
S140-145_31s S140-145_32s S140-145_38s S140-145_39s S140-145_45s S140-145_46s 
        1973         3416         2342         3213         1730         1965 
S140-145_50s S140-145_51s S140-145_57s S140-145_58s S140-145_65s S140-145_72s 
        1404         1918         2196         2400         2304         6288 
S140-145_79s S140-145_80s S140-145_86s S140-145_87s S140-145_93s S140-145_94s
        5861         2524         2460         2224         2969        13775 
 S146-151_4s  S146-151_5s S146-151_11s S146-151_12s S146-151_18s S146-151_19s 
        1646          845         2598          631         1943         1706
S146-151_25s S146-151_26s S146-151_33s S146-151_40s S146-151_47s S146-151_48s 
        8415         1482         4411         6777         1926         1378
S146-151_52s S146-151_53s S146-151_59s S146-151_60s S146-151_66s S146-151_67s 
         765          395         1239         7917         1563         2087
S146-151_73s S146-151_74s S146-151_81s S146-151_88s S146-151_95s S146-151_96s 
        2694         1565         2472         1203         4166          461


#Getting Reads per UMI Calculation from Summary Files 
#on the cluster
cd /scratch/jms53460/3_2025_Sl
features = read.table('featurecounts/read_counts.tab.summary', header=T, sep = '\t', stringsAsFactors=F, row.names=1)
colnames(features) = sub('SNPsplit.S140.145_S195_L004', 'S140-145', sub('SNPsplit.S146.151_S196_L004', 'S146-151', sub('_SNPsplit.bam', '', colnames(features))))
Sl_3_2025_features = features
save(Sl_3_2025_features, file = "3_2025_Sl_features.RData")

#local computer powershell
scp sapelo2:/scratch/jms53460/3_2025_Sl/3_2025_Sl_features.RData 'C:/Users/julia/OneDrive/Desktop/Grad School/Nelms lab/Bioinformatics/R'

#local computer R
load('3_2025_Sl_features.RData')
Sl_3_2025_features = Sl_3_2025_features[,Sl_meta_3_2025$Sample]
Sl_RperU = Sl_3_2025_features[1,]/colSums(D_Sl_3_2025)
plot(colSums(D_Sl_3_2025),Sl_RperU)

