###Install fastq-multx
ml Miniconda3/23.5.2-0
conda create -p /home/jms53460/Fastq-Multx -c bioconda fastq-multx #when prompted, say 'y'
source activate /home/jms53460/Fastq-Multx/
fastq-multx
conda deactivate


###Demultiplex the raw data

#!/bin/bash
#SBATCH --job-name=Ns_demultiplex                       # Job name
#SBATCH --partition=batch                               # Partition (queue) name
#SBATCH --ntasks=1                                      # Single task job
#SBATCH --cpus-per-task=6                               # Number of cores per task
#SBATCH --mem=50gb                                      # Total memory for job
#SBATCH --time=12:00:00                                 # Time limit hrs:min:sec
#SBATCH --output=/home/jms53460/Ns_dm.out      # Location of standard output file
#SBATCH --error=/home/jms53460/Ns_dm.err       # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                    # Where to send mail
#SBATCH --mail-type=END,FAIL                            # Mail events (BEGIN, END, FAIL, ALL)

cd /home/jms53460
ml Miniconda3/23.5.2-0
source activate /home/jms53460/Fastq-Multx/

for file in Raw_Data/*_R1_*.gz; do
    filename=$(basename "$file")
    file2=$(echo "$filename" | sed 's/_R1.*//' | sed 's/_R2_001.fastq.gz//')

    if [ ! -f "Mapped_Data/demultiplexed/""$file2""_dT-1s.fastq.gz" ]; then
        module load fastp/0.23.2-GCC-11.3.0
	    fastp -w 6 -i "$file" -I "Raw_Data/""$file2""_R2_001.fastq.gz" -o "Mapped_Data/demultiplexed/umi_""$file2""_R1.fastq.gz" -O "Mapped_Data/demultiplexed/umi_""$file2""_R2.fastq.gz" -A -Q -L -G --umi --umi_loc read2 --umi_len 10 --umi_prefix UMI

	    fastq-multx -b -B "CELSeq_barcodes.txt" -m 0 "Mapped_Data/demultiplexed/umi_""$file2""_R2.fastq.gz" "Mapped_Data/demultiplexed/umi_""$file2""_R1.fastq.gz" -o "Mapped_Data/demultiplexed/""$file2""_%_R2.fastq.gz" "Mapped_Data/demultiplexed/""$file2""_%.fastq.gz"  # Split read 2 file by CELseq barcodes. Require perfect match to barcode in expected location

	    find "Mapped_Data/demultiplexed/" -name "umi_*" -delete
	    find "Mapped_Data/demultiplexed/" -name "*s_R2*" -delete
    fi
done
conda deactivate


###Downloaded current Nicotiana sylvestris genome from NCBI and used FileZilla to transfer to the cluster


#Make hisat2 index (hisat2-build), filter (fastp), map to genome (hisat2), .bam output (samtools view), sort (samtools sort)

#!/bin/bash
#SBATCH --job-name=Ns_fastp_hisat2                      # Job name
#SBATCH --partition=batch                               # Partition (queue) name
#SBATCH --ntasks=1                                      # Single task job
#SBATCH --cpus-per-task=6                               # Number of cores per task
#SBATCH --mem=50gb                                      # Total memory for job
#SBATCH --time=12:00:00                                 # Time limit hrs:min:sec
#SBATCH --output=/home/jms53460/Ns_fh2.out              # Location of standard output file
#SBATCH --error=/home/jms53460/Ns_fh2.err               # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                    # Where to send mail
#SBATCH --mail-type=END,FAIL                            # Mail events (BEGIN, END, FAIL, ALL)

cd /home/jms53460
ml HISAT2/3n-20201216-gompi-2022a
hisat2-build Ns_genome.fna Ns_hisat2_index
mkdir hisat2_out

for file in "Mapped_Data/demultiplexed/"*.fastq*
do
	file2="${file:26:-9}"

if [ ! -f "hisat2_out/""$file2"".bam" ]; then

	module load fastp/0.23.2-GCC-11.3.0
	fastp -w 6 -i "$file" -o "hisat2_out/""$file2"".fastq.gz" -y -x -3 -a AAAAAAAAAAAA

	module load SAMtools/1.16.1-GCC-11.3.0
	hisat2 -p 6 --dta -x /home/jms53460/Ns_hisat2_index -U "hisat2_out/""$file2"".fastq.gz" | samtools view -bS -> "hisat2_out/""$file2""_unsorted.bam"
	samtools sort -@ 8 "hisat2_out/""$file2""_unsorted.bam" -o "hisat2_out/""$file2"".bam"
	
fi
done


###Assemble transcripts with stringtie
#!/bin/bash
#SBATCH --job-name=Ns_stringtie                         # Job name
#SBATCH --partition=batch                               # Partition (queue) name
#SBATCH --ntasks=1                                      # Single task job
#SBATCH --cpus-per-task=6                               # Number of cores per task
#SBATCH --mem=50gb                                      # Total memory for job
#SBATCH --time=12:00:00                                 # Time limit hrs:min:sec
#SBATCH --output=/home/jms53460/Ns_stringtie.out        # Location of standard output file
#SBATCH --error=/home/jms53460/Ns_stringtie.err         # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                    # Where to send mail
#SBATCH --mail-type=END,FAIL                            # Mail events (BEGIN, END, FAIL, ALL)

for file in "hisat2_out/"*.bam
do
	ml StringTie/2.2.1-GCC-11.3.0
	stringtie -p 4 -G /scratch/jms53460/2022_SGT_paper_JG_Pollen/Zm-B73-REFERENCE-NAM-5.0_Zm00001eb.1.gff3 --rf -o "stringtie_out2/""${file:11:-4}"".gtf" "$file"
done

# Merge StringTie transcripts

cd $SLURM_SUBMIT_DIR
ls -1 "stringtie_out2/"*.gtf | gawk '{print $0}' > mergelist.txt

# Load StringTie module
ml StringTie/2.2.1-GCC-11.3.0

# Merge GTF files
stringtie --merge -p 8 -G /scratch/jms53460/2022_SGT_paper_JG_Pollen/Zm-B73-REFERENCE-NAM-5.0_Zm00001eb.1.gff3 -o "stringtie_out2/stringtie_merged.gtf" mergelist.txt

# Remove mergelist.txt
rm mergelist.txt
