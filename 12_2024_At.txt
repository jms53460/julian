Transfering Dec2024seq data onto the cluster and backing it up
ssh jms53460@xfer.gacrc.uga.edu
cd /work/bnlab
mkdir Dec2024seq
cd Dec2024seq
ftp 38.122.175.98 2223
#enter the username: Brad.Nelms
#enter the password: Un8Czp
#the code they gave us to use for downloading the files with ftp didn't work at all.
get NE56-12-S12_S166_L007_R2_001.fastq.gz
get NE56-14-M_S178_L007_R1_001.fastq.gz
get S72-21-13-no2_S130_L007_R1_001.fastq.gz 
get NE56-12-S1_S168_L007_R1_001.fastq.gz 
get S72-21-9_S144_L007_R2_001.fastq.gz
get M72-3_S160_L007_R2_001.fastq.gz 
get S72-21-16-no2_S133_L007_R1_001.fastq.gz
get S72-21-4-no3_S131_L007_R1_001.fastq.gz
get S72-21-11_S143_L007_R2_001.fastq.gz
get NE56-12-S3_S170_L007_R1_001.fastq.gz
get M72-3_S160_L007_R1_001.fastq.gz 
get NE56-12-S1_S168_L007_R2_001.fastq.gz 
get S72-21-9_S144_L007_R1_001.fastq.gz 
get NE56-14-M_S178_L007_R2_001.fastq.gz 
get NE56-12-S12_S166_L007_R1_001.fastq.gz 
get S72-21-13-no2_S130_L007_R2_001.fastq.gz 
get S72-21-11_S143_L007_R1_001.fastq.gz
get NE56-12-S3_S170_L007_R2_001.fastq.gz 
get S72-21-4-no3_S131_L007_R2_001.fastq.gz
get S72-21-16-no2_S133_L007_R2_001.fastq.gz 
get S26-37_S190_L007_R1_001.fastq.gz
get NE56-12-S8_S180_L007_R1_001.fastq.gz
get A268-287_S187_L007_R2_001.fastq.gz
get NE56-12-S4_S181_L007_R2_001.fastq.gz
get NE56-3-M_S174_L007_R1_001.fastq.gz 
get S72-3-8_S162_L007_R2_001.fastq.gz 
get S72-21-3_S154_L007_R1_001.fastq.gz
get A268-287_S187_L007_R1_001.fastq.gz
get S26-37_S190_L007_R2_001.fastq.gz 
get NE56-12-S8_S180_L007_R2_001.fastq.gz
get S72-3-8_S162_L007_R1_001.fastq.gz 
get S72-21-3_S154_L007_R2_001.fastq.gz
get NE56-12-S4_S181_L007_R1_001.fastq.gz
get NE56-3-M_S174_L007_R2_001.fastq.gz
get NE56-12-S13_S165_L007_R1_001.fastq.gz
get S72-21-8-no2_S134_L007_R2_001.fastq.gz
get S72-21-5-no2_S138_L007_R2_001.fastq.gz
get M72-3_S159_L007_R1_001.fastq.gz
get S72-21-8-no2_S134_L007_R1_001.fastq.gz
get NE56-12-S13_S165_L007_R2_001.fastq.gz
get M72-3_S159_L007_R2_001.fastq.gz
get S72-21-5-no2_S138_L007_R1_001.fastq.gz
get S72-21-7-no2_S146_L007_R2_001.fastq.gz
get NE56-12-S7_S169_L007_R1_001.fastq.gz
get S72-21-1-no2_S126_L007_R1_001.fastq.gz
get M72-21_S128_L007_R1_001.fastq.gz
get M72-21-1_S147_L007_R1_001.fastq.gz
get S72-3-6_S158_L007_R2_001.fastq.gz
get S72-21-2-no3_S127_L007_R1_001.fastq.gz
get NE56-12-M2_S177_L007_R2_001.fastq.gz
get S72-21-11-no2_S135_L007_R1_001.fastq.gz
get M72-21-1_S147_L007_R2_001.fastq.gz
get M72-21_S128_L007_R2_001.fastq.gz
get S72-3-6_S158_L007_R1_001.fastq.gz
get S72-21-1-no2_S126_L007_R2_001.fastq.gz
get S72-21-7-no2_S146_L007_R1_001.fastq.gz
get NE56-12-S7_S169_L007_R2_001.fastq.gz
get S72-21-11-no2_S135_L007_R2_001.fastq.gz
get NE56-12-M2_S177_L007_R1_001.fastq.gz
get S72-21-2-no3_S127_L007_R2_001.fastq.gz
get S72-21-18_S157_L007_R2_001.fastq.gz
get A288-301_S188_L007_R2_001.fastq.gz
get NE56-12-S11_S175_L007_R2_001.fastq.gz
get S72-21-8-no3_S155_L007_R2_001.fastq.gz
get NE56-3-S1_S173_L007_R2_001.fastq.gz
get NE56-3-M2_S182_L007_R2_001.fastq.gz
get S72-21-5-no3_S132_L007_R2_001.fastq.gz
get S72-21-9-no2_S136_L007_R1_001.fastq.gz
get NE56-3-S11_S186_L007_R2_001.fastq.gz
get S72-3-11_S164_L007_R1_001.fastq.gz
get S72-21-3-no2_S141_L007_R2_001.fastq.gz
get S72-21-4-no2_S140_L007_R1_001.fastq.gz
get S72-21-7-no3_S150_L007_R1_001.fastq.gz
get S72-21-2-no3_S129_L007_R1_001.fastq.gz
get NE56-3-S1_S173_L007_R1_001.fastq.gz
get S72-21-8-no3_S155_L007_R1_001.fastq.gz
get NE56-12-S11_S175_L007_R1_001.fastq.gz 
get A288-301_S188_L007_R1_001.fastq.gz
get S72-21-18_S157_L007_R1_001.fastq.gz
get S72-21-7-no3_S150_L007_R2_001.fastq.gz
get S72-21-2-no3_S129_L007_R2_001.fastq.gz
get S72-3-11_S164_L007_R2_001.fastq.gz
get S72-21-3-no2_S141_L007_R1_001.fastq.gz
get S72-21-4-no2_S140_L007_R2_001.fastq.gz
get S72-21-9-no2_S136_L007_R2_001.fastq.gz
get NE56-3-S11_S186_L007_R1_001.fastq.gz
get NE56-3-M2_S182_L007_R1_001.fastq.gz
get S72-21-5-no3_S132_L007_R1_001.fastq.gz
get NE56-3-S6_S171_L007_R1_001.fastq.gz
get S72-21-12_S156_L007_R1_001.fastq.gz
get S72-21-10-no2_S137_L007_R2_001.fastq.gz
get NE56-12-S6_S179_L007_R1_001.fastq.gz
get L66-5_S500_L007_R2_001.fastq.gz
get S72-3-4_S161_L007_R2_001.fastq.gz
get NE56-12-S6_S179_L007_R2_001.fastq.gz
get S72-21-10-no2_S137_L007_R1_001.fastq.gz
get NE56-3-S6_S171_L007_R2_001.fastq.gz
get S72-21-12_S156_L007_R2_001.fastq.gz
get L66-5_S500_L007_R1_001.fastq.gz
get S72-3-4_S161_L007_R1_001.fastq.gz
get S72-21-12-no2_S152_L007_R2_001.fastq.gz
get S72-21-3-no3_S149_L007_R1_001.fastq.gz
get NE56-12-S16_S183_L007_R2_001.fastq.gz
get S14-25_S189_L007_R1_001.fastq.gz
get S72-21-8_S145_L007_R2_001.fastq.gz
get NE56-12-S14_S172_L007_R2_001.fastq.gz
get S72-21-1-no3_S151_L007_R2_001.fastq.gz
get M72-21-2_S148_L007_R2_001.fastq.gz
get NE56-14-S4_S163_L007_R2_001.fastq.gz
get NE56-12-S16_S183_L007_R1_001.fastq.gz
get S72-21-12-no2_S152_L007_R1_001.fastq.gz
get S72-21-3-no3_S149_L007_R2_001.fastq.gz 
get S72-21-1-no3_S151_L007_R1_001.fastq.gz
get NE56-14-S4_S163_L007_R1_001.fastq.gz
get M72-21-2_S148_L007_R1_001.fastq.gz
get S72-21-8_S145_L007_R1_001.fastq.gz
get NE56-12-S14_S172_L007_R1_001.fastq.gz
get S14-25_S189_L007_R2_001.fastq.gz 
get NE56-14-S6_S176_L007_R1_001.fastq.gz
get S72-21-7_S153_L007_R1_001.fastq.gz
get NE56-12-S15_S167_L007_R2_001.fastq.gz
get S72-21-18-no2_S139_L007_R2_001.fastq.gz
get NE56-3-S19_S184_L007_R1_001.fastq.gz
get S72-21-15_S142_L007_R1_001.fastq.gz 
get NE56-3-S3_S185_L007_R1_001.fastq.gz
get S72-21-6-no2_S125_L007_R1_001.fastq.gz
get NE56-12-S15_S167_L007_R1_001.fastq.gz
get S72-21-7_S153_L007_R2_001.fastq.gz
get NE56-14-S6_S176_L007_R2_001.fastq.gz
get S72-21-6-no2_S125_L007_R2_001.fastq.gz
get md5.txt
get NE56-3-S3_S185_L007_R2_001.fastq.gz
get S72-21-15_S142_L007_R2_001.fastq.gz
get S72-21-18-no2_S139_L007_R1_001.fastq.gz
get NE56-3-S19_S184_L007_R2_001.fastq.gz

mkdir 12_2024_At
mkdir 12_2024_At/Raw_Data
cp /work/bnlab/Dec2024seq/A* /scratch/jms53460/12_2024_At
mkdir 12_2024_Sl
mkdir 12_2024_Sl/Raw_Data
cp /work/bnlab/Dec2024seq/S14* /scratch/jms53460/12_2024_Sl/Raw_Data
cp /work/bnlab/Dec2024seq/S26* /scratch/jms53460/12_2024_Sl/Raw_Data

scp sapelo2:/scratch/jms53460/12_2024_At/Raw_Data/*.fastq.gz 'D:\12_2024_At_Data'
scp sapelo2:/scratch/jms53460/12_2024_Sl/Raw_Data/*.fastq.gz 'D:\12_2024_Sl_Data'

cp -r /home/jms53460/Ler_0_N-masked /scratch/jms53460/12_2024_At/
cp /home/jms53460/CELSeq_barcodes.txt /scratch/jms53460/12_2024_At/
cp /home/jms53460/Ler_SNPs.tab /scratch/jms53460/12_2024_At/
cp /home/jms53460/TAIR10.1_Col_5.gff /scratch/jms53460/12_2024_At/




#Demultiplex data in a way that it is nearly ready for upload with SRA.

#!/bin/bash
#SBATCH --job-name=At_dm                                                  # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=6                                                 # Number of cores per task
#SBATCH --mem=50gb                                                        # Total memory for job
#SBATCH --time=6:00:00                                                    # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/12_2024_At/At_dm.out                   # Location of standard output file
#SBATCH --error=/scratch/jms53460/12_2024_At/At_dm.err                    # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/12_2024_At/
mkdir Demultiplexed
ml Miniconda3/23.5.2-0
source activate /home/jms53460/Fastq-Multx

for file in Raw_Data/*_R1_*.gz; do
    filename=$(basename "$file")
    file2=$(echo "$filename" | sed 's/_R1.*//' | sed 's/_R2_001.fastq.gz//')

    if [ ! -f "Demultiplexed/""$file2""_1s.fastq.gz" ]; then
        module load fastp/0.23.2-GCC-11.3.0
	    fastp -w 6 -i "$file" -I "Raw_Data/""$file2""_R2_001.fastq.gz" -o "Demultiplexed/umi_""$file2""_R1.fastq.gz" -O "Demultiplexed/umi_""$file2""_R2.fastq.gz" -A -Q -L -G --umi --umi_loc read2 --umi_len 10 --umi_prefix UMI

	    fastq-multx -b -B "CELSeq_barcodes.txt" -m 0 "Demultiplexed/umi_""$file2""_R2.fastq.gz" "Demultiplexed/umi_""$file2""_R1.fastq.gz" "Raw_Data/""$file2""_R2_001.fastq.gz" -o "Demultiplexed/""$file2""_%_R2.fastq.gz" "Demultiplexed/""$file2""_%.fastq.gz" "Demultiplexed/""$file2""_%_umi.fastq.gz" # Split read 2 file by CELseq barcodes. Require perfect match to barcode in expected location

    fi
done
conda deactivate


###nohup: leaves the cluster doing the thing when you leave the wifi


#!/bin/bash
#SBATCH --job-name=At_hisat2                                              # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=6                                                 # Number of cores per task
#SBATCH --mem=100gb                                                       # Total memory for job
#SBATCH --time=6:00:00                                                   # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/12_2024_At/At_hs2.out                  # Location of standard output file
#SBATCH --error=/scratch/jms53460/12_2024_At/At_hs2.err                   # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/12_2024_At/

module load fastp/0.23.2-GCC-11.3.0
mkdir hisat2_out
for file in Demultiplexed/*s.fastq.gz; do
	file2="${file:14:-9}"

if [ ! -f "hisat2_out/""$file2"".bam" ]; then

	fastp -w 6 -i "$file" -o "hisat2_out/""$file2"".fastq.gz" -y -x -3 -a AAAAAAAAAAAA

fi
done

ml HISAT2/3n-20201216-gompi-2022a
ml SAMtools/1.16.1-GCC-11.3.0
for file in hisat2_out/*s.fastq.gz
do
	file2="${file:11:-9}"

if [ ! -f "hisat2_out/""$file2"".bam" ]; then

	hisat2 -p 6 --dta -x Ler_0_N-masked/merged_hisat2_index -U "hisat2_out/""$file2"".fastq.gz" | samtools view -bS -> "hisat2_out/""$file2""_unsorted.bam"
	samtools sort -@ 6 "hisat2_out/""$file2""_unsorted.bam" -o "hisat2_out/""$file2""_s.bam"
    samtools index -@ 6 "hisat2_out/""$file2""_s.bam"
	
fi
done


###Running SNPsplit

#!/bin/bash
#SBATCH --job-name=At_SNPsplit                                                      # Job name
#SBATCH --partition=batch                                                           # Partition (queue) name
#SBATCH --ntasks=1                                                                  # Single task job
#SBATCH --cpus-per-task=6                                                           # Number of cores per task
#SBATCH --mem=50gb                                                                  # Total memory for job
#SBATCH --time=6:00:00                                                              # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/12_2024_At/At_SNPsplit.out                       # Location of standard output file
#SBATCH --error=/scratch/jms53460/12_2024_At/At_SNPsplit.err                        # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                                # Where to send mail
#SBATCH --mail-type=END,FAIL                                                        # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/12_2024_At/
mkdir At_SNPsplit
ml SAMtools/1.16.1-GCC-11.3.0
ml SNPsplit/0.6.0-GCC-11.3.0-Perl-5.34.1
for file in "hisat2_out/"*_s.bam
do
    file2="${file:11:-6}"

    SNPsplit --conflicting -o At_SNPsplit --snp_file Ler_SNPs.tab "$file"
    samtools sort -@ 6 At_SNPsplit/"$file2"_s.allele_flagged.bam -o At_SNPsplit/"$file2"_SNPsplit.bam
    
done

for file in "At_SNPsplit/"*_s.genome1.bam
do
    file2="${file:12:-14}"
    samtools sort -@ 6 "$file" -o At_SNPsplit/"$file2"_SNPsplit_g1.bam
done

for file in "At_SNPsplit/"*_s.genome2.bam
do
    file2="${file:12:-14}"
    samtools sort -@ 6 "$file" -o At_SNPsplit/"$file2"_SNPsplit_g2.bam
done


#!/bin/bash
#SBATCH --job-name=At_features_UMIs                                           # Job name
#SBATCH --partition=batch                                                     # Partition (queue) name
#SBATCH --ntasks=1                                                            # Single task job
#SBATCH --cpus-per-task=6                                                     # Number of cores per task
#SBATCH --mem=50gb                                                            # Total memory for job
#SBATCH --time=6:00:00                                                       # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/12_2024_At/At_features_UMIs.out            # Location of standard output file
#SBATCH --error=/scratch/jms53460/12_2024_At/At_features_UMIs.err             # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                          # Where to send mail
#SBATCH --mail-type=END,FAIL                                                  # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/12_2024_At/
mkdir featurecounts
mkdir bams
mkdir UMIcounts
mkdir UMIcounts_g1
mkdir UMIcounts_g2
ml purge_dups/1.2.5-foss-2021b
ml Miniconda3/23.5.2-0
source activate /home/jms53460/subread-env

featureCounts -T 6 -s 1 -a TAIR10.1_Col_5.gff -t 'gene' -g 'ID' -o featurecounts/read_counts.tab --readExtension5 500 -R BAM At_SNPsplit/*_SNPsplit.bam
featureCounts -T 6 -s 1 -a TAIR10.1_Col_5.gff -t 'gene' -g 'ID' -o featurecounts/read_counts_g1.tab --readExtension5 500 -R BAM At_SNPsplit/*_SNPsplit_g1.bam
featureCounts -T 6 -s 1 -a TAIR10.1_Col_5.gff -t 'gene' -g 'ID' -o featurecounts/read_counts_g2.tab --readExtension5 500 -R BAM At_SNPsplit/*_SNPsplit_g2.bam

conda deactivate

for file in "featurecounts/"*SNPsplit.bam*
do
    file2="${file:14:-22}"
    if [ ! -f "UMIcounts/${file2}.tsv" ]; then

        module load SAMtools/1.16.1-GCC-11.3.0
        samtools sort -@ 6 "$file" -o "bams/$file2"
        samtools index "bams/$file2"

        module load UMI-tools/1.1.2-foss-2022a-Python-3.10.4
        umi_tools count --per-gene --gene-tag=XT --assigned-status-tag=XS -I "bams/$file2" -S "UMIcounts/${file2}.tsv"
    fi
done

for file in "featurecounts/"*g1.bam*
do
    file2="${file:14:-22}"
    if [ ! -f "UMIcounts_g1/${file2}.tsv" ]; then

        module load SAMtools/1.16.1-GCC-11.3.0
        samtools sort -@ 6 "$file" -o "bams/$file2"
        samtools index "bams/$file2"

        module load UMI-tools/1.1.2-foss-2022a-Python-3.10.4
        umi_tools count --per-gene --gene-tag=XT --assigned-status-tag=XS -I "bams/$file2" -S "UMIcounts_g1/${file2}.tsv"
    fi
done

for file in "featurecounts/"*g2.bam*
do
    file2="${file:14:-22}"
    if [ ! -f "UMIcounts_g2/${file2}.tsv" ]; then

        module load SAMtools/1.16.1-GCC-11.3.0
        samtools sort -@ 6 "$file" -o "bams/$file2"
        samtools index "bams/$file2"

        module load UMI-tools/1.1.2-foss-2022a-Python-3.10.4
        umi_tools count --per-gene --gene-tag=XT --assigned-status-tag=XS -I "bams/$file2" -S "UMIcounts_g2/${file2}.tsv"
    fi
done


ml R/4.3.1-foss-2022a
R
annots = strsplit(read.table('TAIR10.1_Col_5.gff', sep = '\t', quote = "")[,9], ';')
annots = annots[grep('ID=gene-', annots)]
names(annots) = unlist(lapply(annots, function(xx) { xx[1] }))
names(annots) = sub('ID=', '', names(annots))
annots = annots[!duplicated(names(annots))]
annots = sub(';', '', sub(' ', '', unlist(lapply(annots, function(xx) { sub('.+ ', '', if (length(xx) == 3) { xx[3] } else { xx[1] }) }))))

files = dir('UMIcounts')
A = matrix(NA, nrow = length(annots), ncol = length(files))
rownames(A) = annots
colnames(A) = files
for (f in files) {
	xx = read.table(paste('UMIcounts/', f, sep = ''), sep = '\t', header=T, row.names=1)
	A[,f] = xx[match(names(annots),rownames(xx)),1]
}
colnames(A) = sub('L003_', '', sub('_SNPsplit.tsv', '', files))
A[is.na(A)] = 0
#A = A[rowSums(A) > 0,]

B = A[order(rownames(A)),]
B2 = B
B = B[!duplicated(rownames(B)),]
for (g in unique(rownames(B)[duplicated(rownames(B))])) {
	B[g,] = colSums(B2[rownames(B2) %in% g,])
}
D = B

files = dir('UMIcounts_g1')
A = matrix(NA, nrow = length(annots), ncol = length(files))
rownames(A) = annots
colnames(A) = files
for (f in files) {
	xx = read.table(paste('UMIcounts_g1/', f, sep = ''), sep = '\t', header=T, row.names=1)
	A[,f] = xx[match(names(annots),rownames(xx)),1]
}
colnames(A) = sub('L003_', '', sub('_SNPsplit_g1.tsv', '', files))
A[is.na(A)] = 0
#A = A[rowSums(A) > 0,]

B = A[order(rownames(A)),]
B2 = B
B = B[!duplicated(rownames(B)),]
for (g in unique(rownames(B)[duplicated(rownames(B))])) {
	B[g,] = colSums(B2[rownames(B2) %in% g,])
}
g1 = B

files = dir('UMIcounts_g2')
A = matrix(NA, nrow = length(annots), ncol = length(files))
rownames(A) = annots
colnames(A) = files
for (f in files) {
	xx = read.table(paste('UMIcounts_g2/', f, sep = ''), sep = '\t', header=T, row.names=1)
	A[,f] = xx[match(names(annots),rownames(xx)),1]
}
colnames(A) = sub('L003_', '', sub('_SNPsplit_g2.tsv', '', files))
A[is.na(A)] = 0
#A = A[rowSums(A) > 0,]

B = A[order(rownames(A)),]
B2 = B
B = B[!duplicated(rownames(B)),]
for (g in unique(rownames(B)[duplicated(rownames(B))])) {
	B[g,] = colSums(B2[rownames(B2) %in% g,])
}
g2 = B

genes = read.table('TAIR10.1_Col_5.gff', sep = '\t', quote = "")[,c(1,5)]
annots2 = strsplit(read.table('TAIR10.1_Col_5.gff', sep = '\t', quote = "")[,9], ';')
names(annots2) = unlist(lapply(annots2, function(xx) { xx[1] }))
annots2 = sub(';', '', sub(' ', '', unlist(lapply(annots2, function(xx) { sub('.+ ', '', if (length(xx) == 3) { xx[3] } else { xx[1] }) }))))
genes[,3] = annots2
genes2 = genes[grepl('ID=gene-', genes[,3]),]
genes = genes2[order(genes2[,2]),] #order by position
genes = genes[order(genes[,1]),] #order by chr
genes = genes[!duplicated(genes[,3]),]
colnames(genes) = c('Chr', 'Position', 'Gene')
rownames(genes) = genes[,3]

D = D[rownames(genes),]
g1 = g1[rownames(genes),]
g2 = g2[rownames(genes),]

save(D,g1,g2,genes, file = "12_2024_At.RData")
q()



###Copying this to my local computer
scp sapelo2:/scratch/jms53460/12_2024_At/12_2024_At.RData 'C:/Users/julia/OneDrive/Desktop/Grad School/Nelms lab/Bioinformatics/R'

###In local R terminal
setwd('C:/Users/julia/OneDrive/Desktop/Grad School/Nelms lab/Bioinformatics/R')
load('C:/Users/julia/OneDrive/Desktop/Grad School/Nelms lab/Bioinformatics/R/Julian R instance.rda') #This has data from the first 48 Arabidopsis samples I sequenced alongside functions and such that were used for analysis
load('12_2024_At.RData')


plotCell2 = function (cell) 
{
    annotate_figure(ggarrange(plotChr(cell, chr = 1), plotChr(cell, 
        chr = 2), plotChr(cell, chr = 3), plotChr(cell, chr = 4), 
        plotChr(cell, chr = 5), plotScaleBar, ncol = 1, nrow = 6, 
        align = "v", heights = c(rep(1, 5), 0.4)), left = text_grob("          % Transcripts from Col-0 allele", 
        rot = 90, size = 10), top = cell)
}


BIN2 = function (xx, bin = 10^6) 
{
    bin = as.numeric(genes[, 1]) * 10^6 + round(genes[, 2]/bin)
    out = by(xx, bin, colSums)
    out2 = t(matrix(unlist(out), nrow = ncol(g1)))
    colnames(out2) = colnames(g1)
    rownames(out2) = names(out)
    return(out2)
}

library(ggplot2)
library(ggpubr)
g1_bin = BIN2(g1)
g2_bin = BIN2(g2)
g1_frac = g1_bin/(g1_bin + g2_bin)
AlleleFrac = g1_frac
AlleleFrac[(g1_bin+g2_bin) < 10] = NA #remove bins with <10 genoinformative transcripts
#AlleleFrac2 = AlleleFrac[,which(colSums(is.na(AlleleFrac)) <= 50)]
AlleleFrac2 = AlleleFrac[,which(colSums(D) >= 10000)] ###124/192 passed >5000 89/192 passed >= 10000 from 12_2024_At
###478/672 passed >=5000, 318/672 passed >=10000 with the first big data set
###68/160 passed >5000 25/160 passed >= 10000 from 11_2024_At
###124/192 passed >5000 89/192 passed >= 10000 from 12_2024_At

library('ComplexHeatmap')

FracMono = 100*colMeans(abs(AlleleFrac2 - .5) >= .3, na.rm=T)

Heatmap(AlleleFrac2, cluster_rows=F)                   
