#November 2024 data includes 4 strips of tomato and 20 of Arabidopsis. These tomato samples were from the old tomato plant I took cuttings from (24S45-1)
#Downloading data from Duke
ssh jms53460@txfer.gacrc.uga.edu
cd /work/bnlab
mkdir Nov2024Seq
sftp scroggs_10506@dnaseq2.igsp.duke.edu
#enter the password: CSqMHVIA4OHr
get -r Scroggs_10506_241203B9

cp A254-266_S2_L002_R* /home/jms53460/Nov2024Seq/
cp S1-8_A267-277_S3_L002_R* /home/jms53460/Nov2024Seq/

mkdir /scratch/jms53460/11_2024_At
mkdir /scratch/jms53460/11_2024_At/Raw_Data
cp A254-266_S2_L002_R* /scratch/jms53460/11_2024_At/Raw_Data
cp S1-8_A267-277_S3_L002_R* /scratch/jms53460/11_2024_At/Raw_Data

cp -r /home/jms53460/Ler_0_N-masked /scratch/jms53460/11_2024_At/
cp /home/jms53460/CELSeq_barcodes.txt /scratch/jms53460/11_2024_At/
cp /home/jms53460/Ler_SNPs.tab /scratch/jms53460/11_2024_At/
cp /home/jms53460/TAIR10.1_Col_5.gff /scratch/jms53460/11_2024_At/


#Backup raw data
scp sapelo2:/scratch/jms53460/11_2024_At/Raw_Data/*.fastq.gz 'D:\11_2024_At_Sl_Data'



#Prepare demultiplexed data so it is ready for upload with SRA.

#!/bin/bash
#SBATCH --job-name=At_Sl_demultiplex                                         # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=6                                                 # Number of cores per task
#SBATCH --mem=100gb                                                       # Total memory for job
#SBATCH --time=12:00:00                                                   # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/11_2024_At/At_Sl_dm.out                  # Location of standard output file
#SBATCH --error=/scratch/jms53460/11_2024_At/At_Sl_dm.err                   # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/11_2024_At/
mkdir Demultiplexed
ml Miniconda3/23.5.2-0
source activate /home/jms53460/Fastq-Multx

for file in Raw_Data/*_R1_*.gz; do
    filename=$(basename "$file")
    file2=$(echo "$filename" | sed 's/_R1.*//' | sed 's/_R2_001.fastq.gz//')

	    fastq-multx -b -B "CELSeq_barcodes.txt" -m 0 "Raw_Data/""$file2""_R2_001.fastq.gz" "Raw_Data/""$file2""_R1_001.fastq.gz" -o "Demultiplexed/""$file2""_%_R2_001.fastq.gz" "Demultiplexed/""$file2""_%_R1_001.fastq.gz"  # Split read 2 file by CELseq barcodes. Require perfect match to barcode in expected location
	
done


module load fastp/0.23.2-GCC-11.3.0
for file in Demultiplexed/*_R1_*.gz; do
    file2="${file:0:-15}"

        fastp -w 6 -i $file -I "$file2""R2_001.fastq.gz" -o "$file2""_R1.fastq.gz" -O "$file2""_R2.fastq.gz" -A -Q -L -G --umi --umi_loc read2 --umi_len 10 --umi_prefix UMI

done
conda deactivate

#21 mins for 2 sets of 96


#Map to genome (hisat2), .bam output (samtools view), sort (samtools sort), index (samtools index)

#!/bin/bash
#SBATCH --job-name=At_hisat2                                              # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=6                                                 # Number of cores per task
#SBATCH --mem=50gb                                                        # Total memory for job
#SBATCH --time=2:00:00                                                   # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/11_2024_At/At_hs2.out                 # Location of standard output file
#SBATCH --error=/scratch/jms53460/11_2024_At/At_hs2.err                  # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/11_2024_At/
mkdir hisat2_out
ml fastp/0.23.2-GCC-11.3.0
ml HISAT2/3n-20201216-gompi-2022a
ml SAMtools/1.16.1-GCC-11.3.0

for file in "Demultiplexed/"*s__R1.fastq.gz
do
	file2="${file:14:-13}"

if [ ! -f "hisat2_out/""$file2"".bam" ]; then

	fastp -w 6 -i "$file" -o "hisat2_out/""$file2"".fastq.gz" -y -x -3 -a AAAAAAAAAAAA
    hisat2 -p 6 --dta -x Ler_0_N-masked/merged_hisat2_index -U "hisat2_out/""$file2"".fastq.gz" | samtools view -bS -> "hisat2_out/""$file2""_unsorted.bam"
	samtools sort -@ 6 "hisat2_out/""$file2""_unsorted.bam" -o "hisat2_out/""$file2""_s.bam"
    samtools index -@ 6 "hisat2_out/""$file2""_s.bam"
	
fi
done


#Very few reads, trying running fastp and fastq-multx the previous way

#!/bin/bash
#SBATCH --job-name=At_Sl_demultiplex2_hisat                                         # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=6                                                 # Number of cores per task
#SBATCH --mem=100gb                                                       # Total memory for job
#SBATCH --time=6:00:00                                                   # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/11_2024_At/At_Sl_dm2_hs2.out                  # Location of standard output file
#SBATCH --error=/scratch/jms53460/11_2024_At/At_Sl_dm2_hs2.err                   # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/11_2024_At/
mkdir Demultiplexed2
ml Miniconda3/23.5.2-0
source activate /home/jms53460/Fastq-Multx

for file in Raw_Data/*_R1_*.gz; do
    filename=$(basename "$file")
    file2=$(echo "$filename" | sed 's/_R1.*//' | sed 's/_R2_001.fastq.gz//')

    if [ ! -f "Demultiplexed2/""$file2""_1s.fastq.gz" ]; then
        module load fastp/0.23.2-GCC-11.3.0
	    fastp -w 6 -i "$file" -I "Raw_Data/""$file2""_R2_001.fastq.gz" -o "Demultiplexed2/umi_""$file2""_R1.fastq.gz" -O "Demultiplexed2/umi_""$file2""_R2.fastq.gz" -A -Q -L -G --umi --umi_loc read2 --umi_len 10 --umi_prefix UMI

	    fastq-multx -b -B "CELSeq_barcodes.txt" -m 0 "Demultiplexed2/umi_""$file2""_R2.fastq.gz" "Demultiplexed2/umi_""$file2""_R1.fastq.gz" -o "Demultiplexed2/""$file2""_%_R2.fastq.gz" "Demultiplexed2/""$file2""_%.fastq.gz"  # Split read 2 file by CELseq barcodes. Require perfect match to barcode in expected location

	    find "Demultiplexed2/" -name "umi_*" -delete
	    find "Demultiplexed2/" -name "*_R2*" -delete
    fi
done
conda deactivate

ml HISAT2/3n-20201216-gompi-2022a
mkdir hisat2_out2

for file in "Demultiplexed2/"*.fastq*
do
	file2="${file:15:-9}"

if [ ! -f "hisat2_out2/""$file2"".bam" ]; then

	module load fastp/0.23.2-GCC-11.3.0
	fastp -w 6 -i "$file" -o "hisat2_out2/""$file2"".fastq.gz" -y -x -3 -a AAAAAAAAAAAA

fi
done

ml SAMtools/1.16.1-GCC-11.3.0
for file in "hisat2_out2/"*s.fastq*
do
	file2="${file:12:-9}"

if [ ! -f "hisat2_out2/""$file2"".bam" ]; then

	hisat2 -p 6 --dta -x Ler_0_N-masked/merged_hisat2_index -U "hisat2_out2/""$file2"".fastq.gz" | samtools view -bS -> "hisat2_out2/""$file2""_unsorted.bam"
	samtools sort -@ 6 "hisat2_out2/""$file2""_unsorted.bam" -o "hisat2_out2/""$file2""_s.bam"
    samtools index -@ 6 "hisat2_out2/""$file2""_s.bam"
	
fi
done


#Retrying doing demultiplexing first with modified code

rm -r Demultiplexed

#!/bin/bash
#SBATCH --job-name=At_Sl_demultiplex                                         # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=6                                                 # Number of cores per task
#SBATCH --mem=50gb                                                       # Total memory for job
#SBATCH --time=2:00:00                                                   # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/11_2024_At/At_Sl_dm.out                  # Location of standard output file
#SBATCH --error=/scratch/jms53460/11_2024_At/At_Sl_dm.err                   # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/11_2024_At/
mkdir Demultiplexed
ml Miniconda3/23.5.2-0
source activate /home/jms53460/Fastq-Multx

module load fastp/0.23.2-GCC-11.3.0
if [ ! -f "Demultiplexed/""$file2""_1s.fastq.gz" ]; then
    for file in Raw_Data/*_R1_*.gz; do
        filename=$(basename "$file")
        file2=$(echo "$filename" | sed 's/_R1.*//' | sed 's/_R2_001.fastq.gz//')

	    fastp -w 6 -i "$file" -I "Raw_Data/""$file2""_R2_001.fastq.gz" -o "Demultiplexed/fastp_""$file2""_R1.fastq.gz" -O "Demultiplexed/fastp_""$file2""_R2.fastq.gz" -A -Q -L -G

	    fastq-multx -b -B "CELSeq_barcodes.txt" -m 0 "Demultiplexed/fastp_""$file2""_R2.fastq.gz" "Demultiplexed/fastp_""$file2""_R1.fastq.gz" -o "Demultiplexed/""$file2""_%_R2_dm.fastq.gz" "Demultiplexed/""$file2""_%_R1_dm.fastq.gz"  # Split read 2 file by CELseq barcodes. Require perfect match to barcode in expected location
    done

    for file in Demultiplexed/*_R1_dm.fastq.gz; do
        file2="${file:0:-15}"
        fastp -w 6 -i "$file" -I "$file2""_R2_dm.fastq.gz" -o "$file2"".fastq.gz" -O "$file2""_R2.fastq.gz" -A -Q -L -G --umi --umi_loc read2 --umi_len 10 --umi_prefix UMI
        
        #find "Demultiplexed/" -name "*_dm*" -delete
        #find "Demultiplexed/" -name "fastp_*" -delete
    done
fi

conda deactivate

#Files still strangely small, too few lines per file. Going back to original order but not deleting R2.



#!/bin/bash
#SBATCH --job-name=At_Sl_demultiplex                                         # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=6                                                 # Number of cores per task
#SBATCH --mem=50gb                                                       # Total memory for job
#SBATCH --time=2:00:00                                                   # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/11_2024_At/At_Sl_dm3.out                  # Location of standard output file
#SBATCH --error=/scratch/jms53460/11_2024_At/At_Sl_dm3.err                   # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/11_2024_At/
mkdir Demultiplexed3
ml Miniconda3/23.5.2-0
source activate /home/jms53460/Fastq-Multx

for file in Raw_Data/*_R1_*.gz; do
    filename=$(basename "$file")
    file2=$(echo "$filename" | sed 's/_R1.*//' | sed 's/_R2_001.fastq.gz//')

    if [ ! -f "Demultiplexed3/""$file2""_1s.fastq.gz" ]; then
        module load fastp/0.23.2-GCC-11.3.0
	    fastp -w 6 -i "$file" -I "Raw_Data/""$file2""_R2_001.fastq.gz" -o "Demultiplexed3/umi_""$file2""_R1.fastq.gz" -O "Demultiplexed3/umi_""$file2""_R2.fastq.gz" -A -Q -L -G --umi --umi_loc read2 --umi_len 10 --umi_prefix UMI

	    fastq-multx -b -B "CELSeq_barcodes.txt" -m 0 "Demultiplexed3/umi_""$file2""_R2.fastq.gz" "Demultiplexed3/umi_""$file2""_R1.fastq.gz" -o "Demultiplexed3/""$file2""_%_R2.fastq.gz" "Demultiplexed3/""$file2""_%.fastq.gz"  # Split read 2 file by CELseq barcodes. Require perfect match to barcode in expected location

	    find "Demultiplexed3/" -name "umi_*" -delete

    fi
done
conda deactivate


#Trying to similuate losing the header and then trying to run fastp to readd UMI info.
cp Demultiplexed3/A254-266_S2_L002_1s.fastq.gz .
cp Demultiplexed3/A254-266_S2_L002_1s_R2.fastq.gz .
zcat A254-266_S2_L002_1s.fastq.gz | sed 's/UMI_.* / /' | head
zcat A254-266_S2_L002_1s.fastq.gz | sed 's/@.*/@/' > A254-266_S2_L002_1s_stripped.fastq
zcat A254-266_S2_L002_1s_R2.fastq.gz | sed 's/@.*/@/' > A254-266_S2_L002_1s_R2_stripped.fastq
gzip A254-266_S2_L002_1s_stripped.fastq
gzip A254-266_S2_L002_1s_R2_stripped.fastq
fastp -w 6 -i A254-266_S2_L002_1s_stripped.fastq.gz -I A254-266_S2_L002_1s_R2_stripped.fastq.gz -o A254-266_S2_L002_1s_umi.fastq.gz -O A254-266_S2_L002_1s_R2_umi.fastq.gz -A -Q -L -G --umi --umi_loc read2 --umi_len 10 --umi_prefix UMI
#fastp deletes the UMIs from the read sequence when it moves them to the header


conda create -p /home/jms53460/demultiplex -y
source activate /home/jms53460/demultiplex
pip install demultiplex #An error saying umi-tools requires future popped up. demultiplex-1.2.2
pip install future #future-1.0.0
demultiplex
conda deactivate


#!/bin/bash
#SBATCH --job-name=At_Sl_demultiplex                                         # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=1                                                 # Number of cores per task
#SBATCH --mem=100gb                                                       # Total memory for job
#SBATCH --time=48:00:00                                                   # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/11_2024_At/At_Sl_dm3.out                  # Location of standard output file
#SBATCH --error=/scratch/jms53460/11_2024_At/At_Sl_dm3.err                   # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/11_2024_At/
mkdir Demultiplexed3
ml Miniconda3/23.5.2-0
source activate /home/jms53460/demultiplex

for file in Raw_Data/*_R1_*.gz; do
    filename=$(basename "$file")
    file2=$(echo "$filename" | sed 's/_R1.*//' | sed 's/_R2_001.fastq.gz//')

    if [ ! -f "Demultiplexed3/""$file2""_1s.fastq.gz" ]; then
      
	    demultiplex match -m 0 -p Demultiplexed3 "CELSeq_barcodes.txt" "$file" "Raw_Data/""$file2""_R2_001.fastq.gz" # Split read 2 file by CELseq barcodes. Require perfect match to barcode in expected location

    fi
done
conda deactivate



#Move the tomato data to a different directory
mkdir /scratch/jms53460/11_2024_Sl
mkdir /scratch/jms53460/11_2024_Sl/Demultiplexed
cd Demultiplexed3
mv S1-8_A267-277_S3_L002_R*_001_1* /scratch/jms53460/11_2024_Sl/Demultiplexed
mv S1-8_A267-277_S3_L002_R*_001_2* /scratch/jms53460/11_2024_Sl/Demultiplexed
mv S1-8_A267-277_S3_L002_R*_001_3s* /scratch/jms53460/11_2024_Sl/Demultiplexed
mv S1-8_A267-277_S3_L002_R*_001_4s* /scratch/jms53460/11_2024_Sl/Demultiplexed
mv S1-8_A267-277_S3_L002_R*_001_5s* /scratch/jms53460/11_2024_Sl/Demultiplexed
mv S1-8_A267-277_S3_L002_R*_001_6s* /scratch/jms53460/11_2024_Sl/Demultiplexed
mv S1-8_A267-277_S3_L002_R*_001_7s* /scratch/jms53460/11_2024_Sl/Demultiplexed
mv S1-8_A267-277_S3_L002_R*_001_8s* /scratch/jms53460/11_2024_Sl/Demultiplexed
mv S1-8_A267-277_S3_L002_R*_001_9s* /scratch/jms53460/11_2024_Sl/Demultiplexed
mv S1-8_A267-277_S3_L002_R*_001_30s* /scratch/jms53460/11_2024_Sl/Demultiplexed
mv S1-8_A267-277_S3_L002_R*_001_31s* /scratch/jms53460/11_2024_Sl/Demultiplexed
mv S1-8_A267-277_S3_L002_R*_001_32s* /scratch/jms53460/11_2024_Sl/Demultiplexed
cp S1-8_A267-277_S3_L002_R*_001_UNKNOWN.fastq.gz /scratch/jms53460/11_2024_Sl/Demultiplexed

cd ..
rm -r hisat2_out


#!/bin/bash
#SBATCH --job-name=At_hisat2                                         # Job name
#SBATCH --partition=batch                                                 # Partition (queue) name
#SBATCH --ntasks=1                                                        # Single task job
#SBATCH --cpus-per-task=6                                                 # Number of cores per task
#SBATCH --mem=100gb                                                       # Total memory for job
#SBATCH --time=12:00:00                                                   # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/11_2024_At/At_hs2.out                  # Location of standard output file
#SBATCH --error=/scratch/jms53460/11_2024_At/At_hs2.err                   # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                      # Where to send mail
#SBATCH --mail-type=END,FAIL                                              # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/11_2024_At/

module load fastp/0.23.2-GCC-11.3.0
mkdir UMI_moved
for file in Demultiplexed3/A254-266*R1*s.fastq.gz; do
        file2="${file:39:-9}"
        fastp -w 6 -i "$file" -I "Demultiplexed3/A254-266_S2_L002_R2_001_""$file2"".fastq.gz" -o "UMI_moved/A254-266_""$file2"".fastq.gz" -O "UMI_moved/A254-266_""$file2""_R2.fastq.gz" -A -Q -L -G --umi --umi_loc read2 --umi_len 10 --umi_prefix UMI
    done
for file in Demultiplexed3/S1-8_A267-277*R1*s.fastq.gz; do
        file2="${file:44:-9}"
        fastp -w 6 -i "$file" -I "Demultiplexed3/S1-8_A267-277_S3_L002_R2_001_""$file2"".fastq.gz" -o "UMI_moved/S1-8_A267-277_""$file2"".fastq.gz" -O "UMI_moved/S1-8_A267-277_""$file2""_R2.fastq.gz" -A -Q -L -G --umi --umi_loc read2 --umi_len 10 --umi_prefix UMI
    done

mkdir hisat2_out

for file in "UMI_moved/"*s.fastq.gz
do
	file2="${file:10:-12}"

if [ ! -f "hisat2_out/""$file2"".bam" ]; then

	fastp -w 6 -i "$file" -o "hisat2_out/""$file2"".fastq.gz" -y -x -3 -a AAAAAAAAAAAA

fi
done

ml HISAT2/3n-20201216-gompi-2022a
ml SAMtools/1.16.1-GCC-11.3.0
for file in "hisat2_out/"*s.fastq.gz
do
	file2="${file:11:-9}"

if [ ! -f "hisat2_out/""$file2"".bam" ]; then

	hisat2 -p 6 --dta -x Ler_0_N-masked/merged_hisat2_index -U "hisat2_out/""$file2"".fastq.gz" | samtools view -bS -> "hisat2_out/""$file2""_unsorted.bam"
	samtools sort -@ 6 "hisat2_out/""$file2""_unsorted.bam" -o "hisat2_out/""$file2""_s.bam"
    samtools index -@ 6 "hisat2_out/""$file2""_s.bam"
	
fi
done





A155-168_S94_L003_R1_001.fastq.gz                                                        100% 5686MB  11.5MB/s   08:16    
A155-168_S94_L003_R2_001.fastq.gz                                                        100% 5512MB  11.4MB/s   08:02    
A182-193_S33_L005_R1_001.fastq.gz                                                        100% 4339MB   8.9MB/s   08:07    
A182-193_S33_L005_R2_001.fastq.gz                                                        100% 4324MB   8.5MB/s   08:31    
A194-205_S34_L005_R1_001.fastq.gz                                                        100% 3957MB   9.8MB/s   06:44    
A194-205_S34_L005_R2_001.fastq.gz                                                        100% 4002MB  12.2MB/s   05:28    
A206-217_S35_L005_R1_001.fastq.gz                                                        100% 2183MB  12.5MB/s   02:54    
A206-217_S35_L005_R2_001.fastq.gz                                                        100% 2174MB  12.8MB/s   02:49    
A218-229_S36_L005_R1_001.fastq.gz                                                        100% 3374MB  12.9MB/s   04:21    
A218-229_S36_L005_R2_001.fastq.gz                                                        100% 3267MB  12.0MB/s   04:32    
A230-241_S37_L005_R1_001.fastq.gz                                                        100% 4296MB  13.3MB/s   05:23    
A230-241_S37_L005_R2_001.fastq.gz                                                        100% 4370MB  13.2MB/s   05:31    
A242-253_S38_L005_R1_001.fastq.gz                                                        100% 3699MB  12.9MB/s   04:47    
A242-253_S38_L005_R2_001.fastq.gz                                                        100% 3821MB  13.2MB/s   04:50    
PS C:\Users\julia\OneDrive\Documents\GitHub\julian> scp sapelo2:/scratch/jms53460/7_2024_Ns/Raw_Data/*.fastq.gz 'D:\7_2024_Ns_Data'
T104-115_S95_L003_R1_001.fastq.gz                                                        100% 5221MB  11.3MB/s   07:42    
T104-115_S95_L003_R2_001.fastq.gz                                                        100% 5351MB  11.2MB/s   07:56    
PS C:\Users\julia\OneDrive\Documents\GitHub\julian> scp sapelo2:/scratch/jms53460/11_2024_At/Raw_Data/*.fastq.gz 'D:\11_2024_At_Sl_Data'
A254-266_S2_L002_R1_001.fastq.gz                                                         100% 1420MB  10.6MB/s   02:14    
A254-266_S2_L002_R2_001.fastq.gz                                                         100% 1370MB  11.1MB/s   02:03    
S1-8_A267-277_S3_L002_R1_001.fastq.gz                                                    100% 1455MB  11.0MB/s   02:11    
S1-8_A267-277_S3_L002_R2_001.fastq.gz                                                    100% 1384MB  12.0MB/s   01:55

~72 GB of data currently. For future runs, each set of 96 (one plate) will probably take 3-5 GB of data.
In addition to the current data, I'll be getting sequencing data from 6 plates Arabidopsis, 10 tomato, 10 tobacco, 10 rice
Assuming 5 GB of data per plate, 36 plates should take 180 GB. 
In total, I probably need about 252 GB of data storage.






###Running SNPsplit

#!/bin/bash
#SBATCH --job-name=At_SNPsplit                                                      # Job name
#SBATCH --partition=batch                                                           # Partition (queue) name
#SBATCH --ntasks=1                                                                  # Single task job
#SBATCH --cpus-per-task=6                                                           # Number of cores per task
#SBATCH --mem=50gb                                                                  # Total memory for job
#SBATCH --time=6:00:00                                                             # Time limit hrs:min:sec
#SBATCH --output=/scratch/jms53460/11_2024_At/At_SNPsplit.out                       # Location of standard output file
#SBATCH --error=/scratch/jms53460/11_2024_At/At_SNPsplit.err                        # Location of error log file
#SBATCH --mail-user=jms53460@uga.edu                                                # Where to send mail
#SBATCH --mail-type=END,FAIL                                                        # Mail events (BEGIN, END, FAIL, ALL)

cd /scratch/jms53460/11_2024_At/
ml SAMtools/1.16.1-GCC-11.3.0
ml SNPsplit/0.6.0-GCC-11.3.0-Perl-5.34.1
for file in "hisat2_out/"*_s.bam
do
    file2="${file:11:-6}"

    SNPsplit --conflicting -o At_SNPsplit --snp_file Ler_SNPs.tab "$file"
    samtools sort -@ 6 At_SNPsplit/"$file2"_s.allele_flagged.bam -o At_SNPsplit/"$file2"_SNPsplit.bam
    
done

for file in "At_SNPsplit/"*_s.genome1.bam
do
    file2="${file:12:-14}"
    samtools sort -@ 6 "$file" -o At_SNPsplit/"$file2"_SNPsplit_g1.bam
done

for file in "At_SNPsplit/"*_s.genome2.bam
do
    file2="${file:12:-14}"
    samtools sort -@ 6 "$file" -o At_SNPsplit/"$file2"_SNPsplit_g2.bam
done




